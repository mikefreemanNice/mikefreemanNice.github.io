<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[skywalking原理]]></title>
    <url>%2F2020%2F01%2F10%2Fskywalking01%2F</url>
    <content type="text"><![CDATA[基本原理我理解的skywalking是通过javaagent+bytebuddy+plugins方式实现的。 javaagentskywalking通过maven-shade-plugin打包，具体配置如下1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;plugin&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;shadedArtifactAttached&gt;false&lt;/shadedArtifactAttached&gt; &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt; &lt;createSourcesJar&gt;true&lt;/createSourcesJar&gt; &lt;shadeSourcesContent&gt;true&lt;/shadeSourcesContent&gt; &lt;transformers&gt; &lt;transformer implementation="org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"&gt; &lt;manifestEntries&gt; &lt;Premain-Class&gt;$&#123;premain.class&#125;&lt;/Premain-Class&gt; &lt;Can-Redefine-Classes&gt;$&#123;can.redefine.classes&#125;&lt;/Can-Redefine-Classes&gt; &lt;Can-Retransform-Classes&gt;$&#123;can.retransform.classes&#125;&lt;/Can-Retransform-Classes&gt; &lt;/manifestEntries&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;artifactSet&gt; &lt;excludes&gt; &lt;exclude&gt;*:gson&lt;/exclude&gt; &lt;exclude&gt;io.grpc:*&lt;/exclude&gt; &lt;exclude&gt;io.netty:*&lt;/exclude&gt; &lt;exclude&gt;io.opencensus:*&lt;/exclude&gt; &lt;exclude&gt;com.google.*:*&lt;/exclude&gt; &lt;exclude&gt;com.google.guava:guava&lt;/exclude&gt; &lt;/excludes&gt; &lt;/artifactSet&gt; &lt;relocations&gt; &lt;relocation&gt; &lt;pattern&gt;$&#123;shade.net.bytebuddy.source&#125;&lt;/pattern&gt; &lt;shadedPattern&gt;$&#123;shade.net.bytebuddy.target&#125;&lt;/shadedPattern&gt; &lt;/relocation&gt; &lt;/relocations&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;net.bytebuddy:byte-buddy&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/versions/9/module-info.class&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; maven-shade-plugin链接 ByteBuddyByteBuddy官网ByteBuddy 字节码生成工具，通过BuyteBuddy在代码执行动作时植入作者想做的事情。 pluginskywalking适配了业界大部分主流的中间件，主要是通过apm-sniffer module下的apm-sdk-plugin来做这件事，这个module也是更新最频繁的，不断适配新的组件。 基本源码解读入口首先我们看到maven-shade-plugin配置的Premain-Class， 1&lt;premain.class&gt;org.apache.skywalking.apm.agent.SkyWalkingAgent&lt;/premain.class&gt; SkyWalkingAgent的premain方法主要做了以下几件事12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273public static void premain(String agentArgs, Instrumentation instrumentation) throws PluginException, IOException &#123; final PluginFinder pluginFinder; try &#123; // 配置相关config，包括通过java javaagent一些启动参数 SnifferConfigInitializer.initialize(agentArgs); // 加载所有plugin，即apm-sdb-plugin module pluginFinder = new PluginFinder(new PluginBootstrap().loadPlugins()); &#125; catch (ConfigNotFoundException ce) &#123; logger.error(ce, "SkyWalking agent could not find config. Shutting down."); return; &#125; catch (AgentPackageNotFoundException ape) &#123; logger.error(ape, "Locate agent.jar failure. Shutting down."); return; &#125; catch (Exception e) &#123; logger.error(e, "SkyWalking agent initialized failure. Shutting down."); return; &#125; // 生成ByteBuddy final ByteBuddy byteBuddy = new ByteBuddy() .with(TypeValidation.of(Config.Agent.IS_OPEN_DEBUGGING_CLASS)); AgentBuilder agentBuilder = new AgentBuilder.Default(byteBuddy) .ignore( nameStartsWith("net.bytebuddy.") .or(nameStartsWith("org.slf4j.")) .or(nameStartsWith("org.groovy.")) .or(nameContains("javassist")) .or(nameContains(".asm.")) .or(nameContains(".reflectasm.")) .or(nameStartsWith("sun.reflect")) .or(allSkyWalkingAgentExcludeToolkit()) .or(ElementMatchers.&lt;TypeDescription&gt;isSynthetic())); JDK9ModuleExporter.EdgeClasses edgeClasses = new JDK9ModuleExporter.EdgeClasses(); try &#123; // 植入ByteBuddy运行时代码 agentBuilder = BootstrapInstrumentBoost.inject(pluginFinder, instrumentation, agentBuilder, edgeClasses); &#125; catch (Exception e) &#123; logger.error(e, "SkyWalking agent inject bootstrap instrumentation failure. Shutting down."); return; &#125; try &#123; agentBuilder = JDK9ModuleExporter.openReadEdge(instrumentation, agentBuilder, edgeClasses); &#125; catch (Exception e) &#123; logger.error(e, "SkyWalking agent open read edge in JDK 9+ failure. Shutting down."); return; &#125; agentBuilder .type(pluginFinder.buildMatch()) .transform(new Transformer(pluginFinder)) .with(AgentBuilder.RedefinitionStrategy.RETRANSFORMATION) .with(new Listener()) .installOn(instrumentation); try &#123; // 启动相关服务，即所有实现BootService的接口 ServiceManager.INSTANCE.boot(); &#125; catch (Exception e) &#123; logger.error(e, "Skywalking agent boot failure."); &#125; // 配置shutdownhook Runtime.getRuntime().addShutdownHook(new Thread(new Runnable() &#123; @Override public void run() &#123; ServiceManager.INSTANCE.shutdown(); &#125; &#125;, "skywalking service shutdown thread")); &#125; plugin扫描plugin扫描类似于spring boot的spring.factories扫描，当然springboot是通过spring.factories做SPI。而Skywalking使用JDK本身的SPI方式。具体扫描过程如下：1pluginFinder = new PluginFinder(new PluginBootstrap().loadPlugins()); 12345678public List&lt;AbstractClassEnhancePluginDefine&gt; loadPlugins() throws AgentPackageNotFoundException &#123; AgentClassLoader.initDefaultLoader(); PluginResourcesResolver resolver = new PluginResourcesResolver(); List&lt;URL&gt; resources = resolver.getResources(); ... return plugins;&#125; 123456789101112131415161718public List&lt;URL&gt; getResources() &#123; List&lt;URL&gt; cfgUrlPaths = new ArrayList&lt;URL&gt;(); Enumeration&lt;URL&gt; urls; try &#123; urls = AgentClassLoader.getDefault().getResources("skywalking-plugin.def"); while (urls.hasMoreElements()) &#123; URL pluginUrl = urls.nextElement(); cfgUrlPaths.add(pluginUrl); logger.info("find skywalking plugin define in &#123;&#125;", pluginUrl); &#125; return cfgUrlPaths; &#125; catch (IOException e) &#123; logger.error("read resources failure.", e); &#125; return null;&#125; 由此可见skywalking是通过扫描skywalking-plugin.def来进行插件的装载。 SpringCloud plugin这里以springcloud中NetflixFeignInstrumentation为例。 首先skywalking-plugin.def中定义插件入口1spring-cloud-feign-1.x=org.apache.skywalking.apm.plugin.spring.cloud.netflix.feign.v11.define.NetflixFeignInstrumentation 12345678910111213141516171819202122232425262728293031323334353637public class NetflixFeignInstrumentation extends ClassInstanceMethodsEnhancePluginDefine &#123; /** * Enhance class. */ private static final String ENHANCE_CLASS = "org.springframework.cloud.netflix.feign.ribbon.LoadBalancerFeignClient"; /** * Intercept class. */ private static final String INTERCEPT_CLASS = "org.apache.skywalking.apm.plugin.feign.http.v9.DefaultHttpClientInterceptor"; @Override protected ClassMatch enhanceClass() &#123; return byName(ENHANCE_CLASS); &#125; @Override public ConstructorInterceptPoint[] getConstructorsInterceptPoints() &#123; return new ConstructorInterceptPoint[0]; &#125; @Override public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() &#123; return new InstanceMethodsInterceptPoint[] &#123; new InstanceMethodsInterceptPoint() &#123; @Override public ElementMatcher&lt;MethodDescription&gt; getMethodsMatcher() &#123; return named("execute"); &#125; @Override public String getMethodsInterceptor() &#123; return INTERCEPT_CLASS; &#125; @Override public boolean isOverrideArgs() &#123; return false; &#125; &#125; &#125;; &#125;&#125; 通过对org.springframework.cloud.netflix.feign.ribbon.LoadBalancerFeignClient的类进行构造器和方法的拦截，植入的拦截类为org.apache.skywalking.apm.plugin.feign.http.v9.DefaultHttpClientInterceptor。这里主要对LoadBalancerFeignClient的execute方法进行字节码重写。 1public class DefaultHttpClientInterceptor implements InstanceMethodsAroundInterceptor 植入的拦截器实现了InstanceMethodsAroundInterceptor接口，其中需要重写三个方法： beforeMethod afterMethod handleMethodException 我们通过org.apache.skywalking.apm.plugin.feign.http.v9.DefaultHttpClientInterceptor的beforeMethod来看看做了什么操作：12345678910111213141516171819202122232425262728293031323334353637383940414243public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class&lt;?&gt;[] argumentsTypes, MethodInterceptResult result) throws Throwable &#123; Request request = (Request) allArguments[0]; URL url = new URL(request.url()); ContextCarrier contextCarrier = new ContextCarrier(); int port = url.getPort() == -1 ? 80 : url.getPort(); String remotePeer = url.getHost() + ":" + port; String operationName = url.getPath(); FeignResolvedURL feignResolvedURL = PathVarInterceptor.URL_CONTEXT.get(); if (feignResolvedURL != null) &#123; try &#123; operationName = operationName.replace(feignResolvedURL.getUrl(), feignResolvedURL.getOriginUrl()); &#125; finally &#123; PathVarInterceptor.URL_CONTEXT.remove(); &#125; &#125; if (operationName.length() == 0) &#123; operationName = "/"; &#125; AbstractSpan span = ContextManager.createExitSpan(operationName, contextCarrier, remotePeer); span.setComponent(ComponentsDefine.FEIGN); Tags.HTTP.METHOD.set(span, request.method()); Tags.URL.set(span, request.url()); SpanLayer.asHttp(span); Field headersField = Request.class.getDeclaredField("headers"); Field modifiersField = Field.class.getDeclaredField("modifiers"); modifiersField.setAccessible(true); modifiersField.setInt(headersField, headersField.getModifiers() &amp; ~Modifier.FINAL); headersField.setAccessible(true); Map&lt;String, Collection&lt;String&gt;&gt; headers = new LinkedHashMap&lt;String, Collection&lt;String&gt;&gt;(); CarrierItem next = contextCarrier.items(); while (next.hasNext()) &#123; next = next.next(); List&lt;String&gt; contextCollection = new LinkedList&lt;String&gt;(); contextCollection.add(next.getHeadValue()); headers.put(next.getHeadKey(), contextCollection); &#125; headers.putAll(request.headers()); headersField.set(request, Collections.unmodifiableMap(headers)); &#125; 这里解释了http调用时trace的信息是如何传输的：通过header进行传递，只不过这里不是通过拦截器的方式，而是在LoadBalancerFeignClient调用execute的方法是，通过ByteBuddy字节码重写来达到将trace信息存入header的目的。 这里额外扩展一下header传入trace信息后，skywalking如何插装springmvc接收？有兴趣读者可以查看org.apache.skywalking.apm.plugin.spring.mvc.v5.define.RestControllerInstrumentation这个类，本质是对Springmvc的注解比如@GetMapping、@PostMapping等等进行插装来接收feign中header的信息。当然，skywalking对不同版本的spring实现都不同。 总结总的来说，skywalking这种方式使用起来方便，但伴随的是开发难度较大，需要对不同组件的底层都由了解才能灵活使用或者封装自己的插件。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Skywalking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mybatis spring 源码解读]]></title>
    <url>%2F2019%2F12%2F17%2Fmybatis-spring01%2F</url>
    <content type="text"><![CDATA[代码版本12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.4-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; MapperScan注解扫描123456@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(MapperScannerRegistrar.class)@Repeatable(MapperScans.class)public @interface MapperScan 引入MapperScannerRegistrar配置 通过registerBeanDefinitions方法引入MapperScannerConfigurer，配置MapperScannerConfigurer的相关参数，相关参数为MapperScan注解所配置， MapperScannerConfigurer内在调用postProcessBeanDefinitionRegistry方法时通过ClassPathMapperScanner进行扫包，ClassPathMapperScanner继承了ClassPathBeanDefinitionScanner重写doScan方法构建beanDefinitions。每个BeanDefinition的class都设置为MapperFactoryBean.class。 MapperFactoryBean中有mapperInterface属性，在Bean实例化阶段会调用构造方法，将mapperInterface设置为项目中interface的class。 MapperFactoryBean继承SqlSessionDaoSupport，SqlSessionDaoSupport继承DaoSupport，DaoSupport在调用afterPropertiesSet方法是会检查Configuration中是否配置了对应Mapper，如果没有添加，则通过MapperRegistry的addMapper方法加入。 MapperFactoryBean的引用如下图：相应代码如下： 123456789101112131415161718@Override protected void checkDaoConfig() &#123; super.checkDaoConfig(); notNull(this.mapperInterface, "Property 'mapperInterface' is required"); Configuration configuration = getSqlSession().getConfiguration(); if (this.addToConfig &amp;&amp; !configuration.hasMapper(this.mapperInterface)) &#123; try &#123; configuration.addMapper(this.mapperInterface); &#125; catch (Exception e) &#123; logger.error("Error while adding the mapper '" + this.mapperInterface + "' to configuration.", e); throw new IllegalArgumentException(e); &#125; finally &#123; ErrorContext.instance().reset(); &#125; &#125; &#125; 12345678910111213141516171819202122 public &lt;T&gt; void addMapper(Class&lt;T&gt; type) &#123; if (type.isInterface()) &#123; if (this.hasMapper(type)) &#123; throw new BindingException("Type " + type + " is already known to the MapperRegistry."); &#125; boolean loadCompleted = false; try &#123; this.knownMappers.put(type, new MapperProxyFactory(type)); MapperAnnotationBuilder parser = new MapperAnnotationBuilder(this.config, type); parser.parse(); loadCompleted = true; &#125; finally &#123; if (!loadCompleted) &#123; this.knownMappers.remove(type); &#125; &#125; &#125;&#125; knownMappers结构为Map&lt;Class&lt;?&gt;, MapperProxyFactory&lt;?&gt;&gt;，因此用做dao的interface都生成了一个代理类。 mybatis执行dao调用过程当我们断点调试时候会发现在代码执行过程中诸如以下配置的mapper的类型都是MapperProxy代理类。12345@Resourceprivate UserMapper userMapper@Autowiredprivate ProductMapper productMapper 其实原因是执行CommonAnnotationBeanPostProcessor或者AutowiredAnnotationBeanPostProcessor通过反射的方式赋值。 我们知道每个dao的interface都被包装成了MapperFacotryBean,在MapperFactoryBean获取bean的时候会执行如下过程 调用getObject方法 1234@Overridepublic T getObject() throws Exception &#123; return getSqlSession().getMapper(this.mapperInterface);&#125; 调用SqlSessionTemplate#getMapper 1234@Overridepublic &lt;T&gt; T getMapper(Class&lt;T&gt; type) &#123; return getConfiguration().getMapper(type, this);&#125; 调用Configuration#getMapper 123public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; return mapperRegistry.getMapper(type, sqlSession);&#125; 调用MapperRegistry#getMapper 1234567891011public &lt;T&gt; T getMapper(Class&lt;T&gt; type, SqlSession sqlSession) &#123; final MapperProxyFactory&lt;T&gt; mapperProxyFactory = (MapperProxyFactory&lt;T&gt;) knownMappers.get(type); if (mapperProxyFactory == null) &#123; throw new BindingException("Type " + type + " is not known to the MapperRegistry."); &#125; try &#123; return mapperProxyFactory.newInstance(sqlSession); &#125; catch (Exception e) &#123; throw new BindingException("Error getting mapper instance. Cause: " + e, e); &#125;&#125; 调用MapperProxyFactory#newInstance生成MapperProxy代理。 12345678protected T newInstance(MapperProxy&lt;T&gt; mapperProxy) &#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &#123; mapperInterface &#125;, mapperProxy);&#125;public T newInstance(SqlSession sqlSession) &#123; final MapperProxy&lt;T&gt; mapperProxy = new MapperProxy&lt;&gt;(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy);&#125; 最后，执行过程会调用MapperProxy的invoke方法，通过MapperMethod#execute来调用SqlSession执行具体语句。]]></content>
      <categories>
        <category>Mybatis</category>
      </categories>
      <tags>
        <tag>Mybatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring cloud config 动态更新]]></title>
    <url>%2F2019%2F07%2F21%2Fdynamic-config%2F</url>
    <content type="text"><![CDATA[简介dynamic-config基于spring cloud config以git为配置中心，实现动态更新的功能，而不需要进行手动refresh或者引入MQ。 项目地址https://github.com/OSInfra/dynamic-config 特征 基于springcloud项目 零配置 使用引入jar12345&lt;dependency&gt; &lt;groupId&gt;com.github.osinfra&lt;/groupId&gt; &lt;artifactId&gt;dynamic-config-client&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 配置bootstrap.yml1234567891011spring: application:name: @app.name@version: @project.version@ profiles:active: @profile@ cloud:config: enabled: true uri: @config url@ label: @git branch@ 项目架构]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你真的了解@Resource和@Autowired吗]]></title>
    <url>%2F2019%2F03%2F08%2Fioc01%2F</url>
    <content type="text"><![CDATA[引言每当我们被问到@Resource和@Autowired的区别，通常会这么回答：@Resource是通过名字注入，@Autowired是通过类型注入。 事实真的如此吗？？？ 问题引入项目中采用spring+mybatis框架,同时引入了zebra(https://github.com/Meituan-Dianping/Zebra)，mybatis采用基于2.0方式。 简略代码如下 1234567891011121314151617181920212223public interface DemoDao&lt;T&gt; &#123; void insert(T t);&#125;@Repositorypublic class DemoDaoImpl implements DemoDao&#123; // 这里T我们不具体写某个实体 @Override public void insert(T t)&#123; return getSqlSession().insert(&quot;demo.insert&quot;, t); &#125;&#125;@Servicepublic class DemoService&#123; @Resource private DemoDao demoDao; public void insert(T t)&#123; demoDao.insert(t); &#125;&#125; mapper如下 1234567&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;demo.test&quot;&gt; &lt;insert id=&quot;insert&quot; &gt; ... &lt;/insert&gt;&lt;/mapper&gt; 如上所示，只是service调用dao，那么结果会调用成功吗？(我们确认mapper配置都没有问题) 结果如下 1org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.test.dao.DemoDao.insert 如果采用@Autowired代替@Resource，结果会一样吗？ 请看下文。 问题分析结果初探我们根据结果首先想到的一个问题是，报错信息是找不到对应的statement：com.test.dao.DemoDao.insert，namespace我们命名配置的是demo.test，那么找statement应该是demo.test.insert，这里却发生了变化。这里还有一个疑问，我们交给spring容器管理的bean name应该是demoDaoImpl而不是demoDao，那么demoDao这个bean从何而来？ zebra分析第一感觉是org.mybatis.spring.SqlSessionFactoryBean这个bean会将接口装载为bean吗？但很遗憾，通过代码查看，它只是对mybatis的configuration进行组装，并不涉及bean的组装。 这时候会返现com.dianping.zebra.dao.mybatis.ZebraMapperScannerConfigurer的引入，这个scanner的作用是扫描package，对一些sql和其它配置做一些封装。代码如下： 123456789101112131415161718192021222324252627public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; if (this.processPropertyPlaceHolders) &#123; processPropertyPlaceHolders(); &#125; String[] beanDefinitionNames = registry.getBeanDefinitionNames(); for (String beanDefinitionName : beanDefinitionNames) &#123; BeanDefinition beanDefinition = registry.getBeanDefinition(beanDefinitionName); String beanClassName = beanDefinition.getBeanClassName(); if(SqlSessionFactoryBean.class.getName().equals(beanClassName))&#123; beanDefinition.setBeanClassName(FixedSqlSessionFactoryBean.class.getName()); &#125; &#125; ZebraClassPathMapperScanner scanner = new ZebraClassPathMapperScanner(registry); scanner.setAddToConfig(this.addToConfig); scanner.setAnnotationClass(this.annotationClass); scanner.setMarkerInterface(this.markerInterface); scanner.setSqlSessionFactory(this.sqlSessionFactory); scanner.setSqlSessionTemplate(this.sqlSessionTemplate); scanner.setSqlSessionFactoryBeanName(this.sqlSessionFactoryBeanName); scanner.setSqlSessionTemplateBeanName(this.sqlSessionTemplateBeanName); scanner.setResourceLoader(this.applicationContext); scanner.setBeanNameGenerator(this.nameGenerator); scanner.registerFilters(); scanner.scan(StringUtils.tokenizeToStringArray(this.basePackage, ConfigurableApplicationContext.CONFIG_LOCATION_DELIMITERS)); &#125; 注意一点scanner.registerFilters();这是配置扫描的过滤策略，来跟下代码 1234567891011121314public void registerFilters() &#123; boolean acceptAllInterfaces = true; ... if (acceptAllInterfaces) &#123; // default include filter that accepts all classes addIncludeFilter(new TypeFilter() &#123; public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123; return true; &#125; &#125;); &#125; ... &#125; 有兴趣的读者可以继续查看com.dianping.zebra.dao.mybatis.ZebraClassPathMapperScanner#doScan的代码，其实到这里已经知道了问题，这个scanner在扫包的时候会将满足条件的接口装载为bean，bean名称为接口名称。到这里我们明确了一个问题，我们spring启动时，针对于DemoDao会生成两个实现类，一个是DemoDao,一个是DemoDaoImpl。 （这个问题如果我们采用mybatis3.0的方式其实可以避免） zebra这个scanner其实和spring中org.mybatis.spring.mapper.ClassPathMapperScanner大同小异。 @Resource分析既然有两个实现类，@Resource为什么会注入zebra生成的，而不是用我们自定义的DemoDaoImpl？这个问题我们要回归到spring，spring对@Resource的解析在这个类中：org.springframework.context.annotation.CommonAnnotationBeanPostProcessor。代码如下： 1234567891011121314151617181920212223242526272829303132333435private InjectionMetadata buildResourceMetadata(final Class&lt;?&gt; clazz) &#123; LinkedList&lt;InjectionMetadata.InjectedElement&gt; elements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); Class&lt;?&gt; targetClass = clazz; do &#123; final LinkedList&lt;InjectionMetadata.InjectedElement&gt; currElements = new LinkedList&lt;InjectionMetadata.InjectedElement&gt;(); ReflectionUtils.doWithLocalFields(targetClass, new ReflectionUtils.FieldCallback() &#123; @Override public void doWith(Field field) throws IllegalArgumentException, IllegalAccessException &#123; if (webServiceRefClass != null &amp;&amp; field.isAnnotationPresent(webServiceRefClass)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(&quot;@WebServiceRef annotation is not supported on static fields&quot;); &#125; currElements.add(new WebServiceRefElement(field, field, null)); &#125; else if (ejbRefClass != null &amp;&amp; field.isAnnotationPresent(ejbRefClass)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(&quot;@EJB annotation is not supported on static fields&quot;); &#125; currElements.add(new EjbRefElement(field, field, null)); &#125; else if (field.isAnnotationPresent(Resource.class)) &#123; if (Modifier.isStatic(field.getModifiers())) &#123; throw new IllegalStateException(&quot;@Resource annotation is not supported on static fields&quot;); &#125; if (!ignoredResourceTypes.contains(field.getType().getName())) &#123; currElements.add(new ResourceElement(field, field, null)); &#125; &#125; &#125; &#125;); ...&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041private class ResourceElement extends LookupElement &#123; private final boolean lazyLookup; public ResourceElement(Member member, AnnotatedElement ae, PropertyDescriptor pd) &#123; super(member, pd); Resource resource = ae.getAnnotation(Resource.class); String resourceName = resource.name(); Class&lt;?&gt; resourceType = resource.type(); this.isDefaultName = !StringUtils.hasLength(resourceName); if (this.isDefaultName) &#123; resourceName = this.member.getName(); if (this.member instanceof Method &amp;&amp; resourceName.startsWith(&quot;set&quot;) &amp;&amp; resourceName.length() &gt; 3) &#123; resourceName = Introspector.decapitalize(resourceName.substring(3)); &#125; &#125; else if (embeddedValueResolver != null) &#123; resourceName = embeddedValueResolver.resolveStringValue(resourceName); &#125; if (resourceType != null &amp;&amp; Object.class != resourceType) &#123; checkResourceType(resourceType); &#125; else &#123; // No resource type specified... check field/method. resourceType = getResourceType(); &#125; this.name = resourceName; this.lookupType = resourceType; String lookupValue = (lookupAttribute != null ? (String) ReflectionUtils.invokeMethod(lookupAttribute, resource) : null); this.mappedName = (StringUtils.hasLength(lookupValue) ? lookupValue : resource.mappedName()); Lazy lazy = ae.getAnnotation(Lazy.class); this.lazyLookup = (lazy != null &amp;&amp; lazy.value()); &#125; @Override protected Object getResourceToInject(Object target, String requestingBeanName) &#123; return (this.lazyLookup ? buildLazyResourceProxy(this, requestingBeanName) : getResource(this, requestingBeanName)); &#125; &#125; 大概解释下：@Resource注解会先判断注解是否指定name，如果没有，则会取属性的名称，即@Resource DemoDao demoDao 中的demoDao，如果这个名字找不到bean，则会通过类型来判断。回到最开始的问题，zebra恰好为我们生成了demoDao，所以我们在service中注入了demoDao，而找不到mapper对应的statement。 解决方案： 指定@Resource的name，@Resource(name=”demoDaoImpl”) 将demoDao改名，让其按类型匹配，@Resource private DemoDao test; @Autowired分析我们回归到最开始的问题，当我们代码改为如下，结果会怎么样？ 123456789@Servicepublic class DemoService&#123; @Autowired private DemoDao demoDao; public void insert(T t)&#123; demoDao.insert(t); &#125;&#125; 执行结果： 1org.apache.ibatis.binding.BindingException: Invalid bound statement (not found): com.test.dao.DemoDao.insert 依旧会有这个问题，为什么？ 我们这里有两个bean，对于Autowried来说，当它发现有两个实现类时会报“org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type XXX”，但是在这之前它会优先去找属性字段名称的bean，而在这个例子中它恰好可以找到demoDao的bean，而不是我们自己定义的DemoDaoImpl，因此报错。 解决方案 在DemoDaoImpl上加入注解@Primary，让Autowired优先找这个bean 总结1 看似简单的问题其实很复杂。2 有兴趣的读者可以看看spring对Autowired的解析：org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS 和 Synchronized原理分析]]></title>
    <url>%2F2019%2F02%2F01%2Flock01%2F</url>
    <content type="text"><![CDATA[Java锁介绍在Java并发中，我们最初接触的应该就是synchronized关键字了，但是synchronized属于重量级锁，很多时候会引起性能问题，volatile也是个不错的选择，但是volatile不能保证原子性，只能在某些场合下使用。 像synchronized这种独占锁属于悲观锁，它是在假设一定会发生冲突的，那么加锁恰好有用，除此之外，还有乐观锁，乐观锁的含义就是假设没有发生冲突，那么我正好可以进行某项操作，如果要是发生冲突呢，那我就重试直到成功，乐观锁最常见的就是CAS。 SynchronizedSynchronized三种使用方式众所周知 Synchronized 关键字是解决并发问题常用解决方案，有以下三种使用方式: 同步普通方法，锁的是当前对象。 同步静态方法，锁的是当前 Class 对象。 同步块，锁的是 {} 中的对象。 实现原理JVM 是通过进入、退出对象监视器( Monitor )来实现对方法、同步块的同步的。具体实现是在编译之后在同步方法调用前加入一个 monitor.enter 指令，在退出方法和异常处插入 monitor.exit 的指令。其本质就是对一个对象监视器( Monitor )进行获取，而这个获取过程具有排他性从而达到了同一时刻只能一个线程访问的目的。而对于没有获取到锁的线程将会阻塞到方法入口处，直到获取锁的线程 monitor.exit 之后才能尝试继续获取锁。 原理实践创建一个Test.java123456789public class Test &#123; public static void main(String[] args) &#123; Object lock = new Object(); synchronized (lock)&#123; System.out.println(&quot;Synchronize&quot;); &#125; &#125;&#125; 执行javac Test.java 编译生成Test.class文件执行javap -c Test.class查看具体信息 1234567891011121314151617181920212223242526272829303132333435Compiled from &quot;Test.java&quot;public class Test &#123; public Test(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Object 3: dup 4: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: dup 10: astore_2 11: monitorenter 12: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream; 15: ldc #4 // String Synchronize 17: invokevirtual #5 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 20: aload_2 21: monitorexit 22: goto 30 25: astore_3 26: aload_2 27: monitorexit 28: aload_3 29: athrow 30: return Exception table: from to target type 12 22 25 any 25 28 25 any&#125; 可以看到在同步块的入口和出口分别有 monitorenter,monitorexit 指令。 锁优化synchronized 很多都称之为重量锁，JDK1.6 中对 synchronized 进行了各种优化，为了能减少获取和释放锁带来的消耗引入了偏向锁和轻量锁。 轻量锁当代码进入同步块时，如果同步对象为无锁状态时，当前线程会在栈帧中创建一个锁记录(Lock Record)区域，同时将锁对象的对象头中 Mark Word 拷贝到锁记录中，再尝试使用 CAS 将 Mark Word 更新为指向锁记录的指针。如果更新成功，当前线程就获得了锁。如果更新失败 JVM 会先检查锁对象的 Mark Word 是否指向当前线程的锁记录。如果是则说明当前线程拥有锁对象的锁，可以直接进入同步块。不是则说明有其他线程抢占了锁，如果存在多个线程同时竞争一把锁，轻量锁就会膨胀为重量锁。 解锁轻量锁的解锁过程也是利用 CAS 来实现的，会尝试锁记录替换回锁对象的 Mark Word 。如果替换成功则说明整个同步操作完成，失败则说明有其他线程尝试获取锁，这时就会唤醒被挂起的线程(此时已经膨胀为重量锁)轻量锁能提升性能的原因是：认为大多数锁在整个同步周期都不存在竞争，所以使用 CAS 比使用互斥开销更少。但如果锁竞争激烈，轻量锁就不但有互斥的开销，还有 CAS 的开销，甚至比重量锁更慢。 偏向锁为了进一步的降低获取锁的代价，JDK1.6 之后还引入了偏向锁。偏向锁的特征是:锁不存在多线程竞争，并且应由一个线程多次获得锁。当线程访问同步块时，会使用 CAS 将线程 ID 更新到锁对象的 Mark Word 中，如果更新成功则获得偏向锁，并且之后每次进入这个对象锁相关的同步块时都不需要再次获取锁了。 释放锁当有另外一个线程获取这个锁时，持有偏向锁的线程就会释放锁，释放时会等待全局安全点(这一时刻没有字节码运行)，接着会暂停拥有偏向锁的线程，根据锁对象目前是否被锁来判定将对象头中的 Mark Word 设置为无锁或者是轻量锁状态。轻量锁可以提高带有同步却没有竞争的程序性能，但如果程序中大多数锁都存在竞争时，那偏向锁就起不到太大作用。可以使用 -XX:-userBiasedLocking=false 来关闭偏向锁，并默认进入轻量锁。其他优化 适应性自旋在使用 CAS 时，如果操作失败，CAS 会自旋再次尝试。由于自旋是需要消耗 CPU 资源的，所以如果长期自旋就白白浪费了 CPU。JDK1.6加入了适应性自旋:如果某个锁自旋很少成功获得，那么下一次就会减少自旋。 CAS实现原理CAS底层使用JNI调用C代码实现的，如果你有Hotspot源码，那么在Unsafe.cpp里可以找到它的实现 CAS的问题ABA问题CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。这就是CAS的ABA问题。常见的解决思路是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A-B-A 就会变成1A-2B-3A。目前在JDK的atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大上面我们说过如果CAS不成功，则会原地自旋，如果长时间自旋会给CPU带来非常大的执行开销。 相关文章 https://juejin.im/post/5a5c488e518825733a30ae9d https://juejin.im/post/5a73cbbff265da4e807783f5]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重写Junit Runner]]></title>
    <url>%2F2019%2F01%2F15%2Fjunit01%2F</url>
    <content type="text"><![CDATA[问题背景通过jenkins或者其他ci定时执行junit test，会碰到这种情况，比如某些跨时间的单测会导致不同的结果，如何不侵入代码完成这些异常情况的过滤？ 解决思路通过重写org.junit.runners.BlockJUnit4ClassRunner的ignore逻辑进行过滤。 具体过程由于测试的项目需要集成Spring，单测需要集成spring的环境配置。 构造自己的Runner代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public class TestBlockingRunner extends SpringJUnit4ClassRunner &#123; public TestBlockingRunner(Class&lt;?&gt; klass) throws InitializationError &#123; super(klass); &#125; @Override protected void runChild(FrameworkMethod frameworkMethod, RunNotifier notifier) &#123; Description description = this.describeChild(frameworkMethod); if (isIgnored(frameworkMethod)) &#123; notifier.fireTestIgnored(description); &#125; else &#123; super.runChild(frameworkMethod, notifier); &#125; &#125; @Override protected boolean isIgnored(FrameworkMethod child) &#123; return isIgnored(child.getMethod()) || super.isIgnored(child); &#125; private boolean isIgnored(Method method) &#123; return isIgnored((RunIf) method.getAnnotation(RunIf.class)); &#125; private boolean isIgnored(RunIf runIf) &#123; if (runIf == null) &#123; return false; &#125; else &#123; Class conditionClass = runIf.value(); try &#123; RunIfCondition condition = (RunIfCondition) conditionClass.newInstance(); return !condition.apply(); &#125; catch (InstantiationException | IllegalAccessException var3) &#123; throw new AssertionError(var3); &#125; &#125; &#125;&#125; 这里重新实现了runChild和isIgnored两个方法，通过查找方法的RunIf注解，来判断当前的过滤条件，过滤条件同意实现RunIfCondition接口。 RunIf注解代码如下： 123456@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.METHOD, ElementType.TYPE&#125;)@Documentedpublic @interface RunIf &#123; Class&lt;? extends RunIfCondition&gt; value();&#125; RunIfCondition接口代码如下： 123public interface RunIfCondition &#123; boolean apply();&#125; 过滤条件实现如果我想在某几个时间点不执行junit test，实现逻辑如下： 123456789101112131415161718192021public class TestCondition implements RunIfCondition &#123; // 由于跨天时间执行test有数量变化问题，可以直接过滤这几个时间点 private static final List&lt;Integer&gt; IGNORE_HOURS = Lists.newArrayList(22, 23, 0, 1); // 具体过滤逻辑 @Override public boolean apply() &#123; LocalTime localTime = LocalTime.now(); if (IGNORE_HOURS.contains(localTime.getHour())) &#123; return Boolean.FALSE; &#125; return Boolean.TRUE; &#125;&#125; 单测用例1234567891011121314151617181920@RunWith(TestBlockingRunner.class)@ContextConfiguration(locations = &quot;classpath:applicationContext-dev.xml&quot;)@Rollbackpublic class Test &#123; @Before public void setUp() throws TException &#123; &#125; @Test @RunIf(TestCondition.class) @Transactional @Sql(&quot;/sql/test.sql&quot;) public void test() &#123; // 代码省略 ... System.out.println(&quot;通过改变时间观察是否有输出。&quot;); &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring framework 常用接口介绍]]></title>
    <url>%2F2018%2F11%2F02%2Fspring01-md%2F</url>
    <content type="text"><![CDATA[Spring加载全过程动画展示 BeanPostProcessor接口定义1234567891011121314151617181920212223242526272829303132333435/** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean * initialization callbacks (like InitializingBean&apos;s &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; if * &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet */Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException;/** * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean * initialization callbacks (like InitializingBean&apos;s &#123;@code afterPropertiesSet&#125; * or a custom init-method). The bean will already be populated with property values. * The returned bean instance may be a wrapper around the original. * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean * instance and the objects created by the FactoryBean (as of Spring 2.0). The * post-processor can decide whether to apply to either the FactoryBean or created * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks. * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method, * in contrast to all other BeanPostProcessor callbacks. * @param bean the new bean instance * @param beanName the name of the bean * @return the bean instance to use, either the original or a wrapped one; if * &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked * @throws org.springframework.beans.BeansException in case of errors * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet * @see org.springframework.beans.factory.FactoryBean */Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException; 执行顺序 org.springframework.beans.factory.config.BeanPostProcessor#postProcessBeforeInitialization org.springframework.beans.factory.InitializingBean#afterPropertiesSet org.springframework.beans.factory.config.BeanPostProcessor#postProcessAfterInitialization ApplicationListener接口定义123456789public interface ApplicationListener&lt;E extends ApplicationEvent&gt; extends EventListener &#123; /** * Handle an application event. * @param event the event to respond to */ void onApplicationEvent(E event);&#125; ApplicationEvent ContextRefreshedEvent：ApplicationContext容器初始化或刷新时触发该事件。此处的初始化是指：所有的Bean被成功装载，后处理Bean被检测并激活，所有Singleton Bean 被预实例化，ApplicationContext容器已就绪可用 ContextStartedEvent：当使用ConfigurableApplicationContext(ApplicationContext的子接口）接口的start()方法启动ApplicationContext容器时触发该事件。容器管理声明周期的Bean实例将获得一个指定的启动信号，这在经常需要停止后重新启动的场合比较常见 ContextClosedEvent：当使用ConfigurableApplicationContext接口的close()方法关闭ApplicationContext时触发该事件 ContextStoppedEvent：当使用ConfigurableApplicationContext接口的stop()方法使ApplicationContext容器停止时触发该事件。此处的停止，意味着容器管理生命周期的Bean实例将获得一个指定的停止信号，被停止的Spring容器可再次调用start()方法重新启动 RequestHandledEvent：Web相关事件，只能应用于使用DispatcherServlet的Web应用。在使用Spring作为前端的MVC控制器时，当Spring处理用户请求结束后，系统会自动触发该事件。 Event也可以自定义实现 ApplicationContextAware为何实现ApplicationContextAware可以获取到ApplicationContext? 其实是org.springframework.context.support.ApplicationContextAwareProcessor实现BeanPostProcessor进行处理。 源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172class ApplicationContextAwareProcessor implements BeanPostProcessor &#123; private final ConfigurableApplicationContext applicationContext; private final StringValueResolver embeddedValueResolver; /** * Create a new ApplicationContextAwareProcessor for the given context. */ public ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123; this.applicationContext = applicationContext; this.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory()); &#125; @Override public Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123; AccessControlContext acc = null; if (System.getSecurityManager() != null &amp;&amp; (bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware || bean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware || bean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) &#123; acc = this.applicationContext.getBeanFactory().getAccessControlContext(); &#125; if (acc != null) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123; @Override public Object run() &#123; invokeAwareInterfaces(bean); return null; &#125; &#125;, acc); &#125; else &#123; invokeAwareInterfaces(bean); &#125; return bean; &#125; private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) &#123; return bean; &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab-ci发布项目]]></title>
    <url>%2F2018%2F10%2F14%2Fgitlab02%2F</url>
    <content type="text"><![CDATA[前言这篇文章是即上篇文章的续写http://www.wowfree.cn/2018/10/13/gitlab01/，gitlab作为代码的私有仓库，被大部分公司所使用，gitlab8.0了提供ci功能，为了简单，一般会剔除掉jenkins的引用，本文主要介绍如何通过gitlab-ci编译、打包、发布项目，本文以Java的springboot项目为例。 简单实现首先你需要新建一个springboot的项目，创建过程这里不赘述，如果你想在gitlab-ci发布它，首先需要在它的根路径创建一个.gitlab-ci.yml文件。简单配置如下： 123456789101112131415161718192021222324252627282930313233image: maven:lateststages: - build - package - deploybuild: stage: build script: - echo &quot;=============== 开始编译构建任务 ===============&quot; - mvn compile tags: - springdemopackage: stage: package tags: - springdemo script: - echo &quot;=============== 开始打包任务 ===============&quot; - mvn clean package -Dmaven.test.skip=true only: - masterdeploy: stage: deploy tags: - springdemo script: - echo &quot;=============== 开始部署任务 ===============&quot; only: - master image的选择是你在注册gitlab-runner时选择的 tags是gitlab-runner的tag，可以通过gitlab页面配置是否需要该tag，默认是需要的 only是执行哪个分支，这里可以通过它来实现不同环境的部署。 进阶如何实现项目的发布，首先我们要考虑的是gitlab运行在docker上，我们需要通过免密登录的方式发布到另一台机器，如何配置成了难点.官网给出的方案：https://docs.gitlab.com/ee/ci/ssh_keys/README.html#ssh-keys-when-using-the-docker-executor 。假设我们当前机器的ip为192.168.1.201，我们想发布到192.168.1.202上，首先需要在202的机器上生成公钥和撕咬， 配置192.168.1.202免密登录12vim /etc/ssh/sshd_config 将RSAAuthentication和PubkeyAuthentication注释去掉 1ssh-keygen -t rsa 在~/.ssh的路径下面会看到公钥和私钥，将公钥配置到gitlab的root用户下的ssh key中。 配置gitlab.yml文件在.gitlab.yml文件加入如下配置 123456789101112before_script: - &apos;which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client git -y )&apos; - eval $(ssh-agent -s) - echo &quot;$SSH_PRIVATE_KEY&quot; | tr -d &apos;\r&apos; | ssh-add - &gt; /dev/null - mkdir -p ~/.ssh - chmod 700 ~/.ssh - ssh-keyscan &quot;$ip&quot; &gt;&gt; ~/.ssh/known_hosts - chmod 644 ~/.ssh/known_hosts SSH_PRIVATE_KEY是配置在gitlab项目中的环境变量，通过页面项目中setting -&gt; CI/CD -&gt; Variables中配置，key是SSH_PRIVATE_KEY，value是192.168.1.202的私钥。 发布项目12345678910111213141516171819202122232425262728293031323334353637before_script: - &apos;which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client git -y )&apos; - eval $(ssh-agent -s) - echo &quot;$SSH_PRIVATE_KEY&quot; | tr -d &apos;\r&apos; | ssh-add - &gt; /dev/null - mkdir -p ~/.ssh - chmod 700 ~/.ssh - ssh-keyscan &quot;$ip&quot; &gt;&gt; ~/.ssh/known_hosts - chmod 644 ~/.ssh/known_hosts stages: - build - deploybuild: image: maven:latest stage: build script: - echo &quot;=============== 开始编译构建任务 ===============&quot; - mvn compile tags: - springdemodeploy: image: maven:latest stage: deploy tags: - springdemo script: - echo &quot;=============== 开始部署任务 ===============&quot; - mvn clean package -Dmaven.test.skip=true -Pdev -B &amp;&amp; scp /builds/java/springclouddemo/web/target/web.jar $&#123;username&#125;@$&#123;ip&#125;:/home/work/web.jar - ssh -T $&#123;username&#125;@$&#123;ip&#125; sh /home/command/start.sh only: - master username和ip为gitlab-ci的变量配置， start.sh脚本如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#! /bin/shWEB_APP=&quot;web&quot;CUSTOM_JVM_OFFLINE=&quot; -Xmx2048m -Xms2048m -Xmn756m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+ExplicitGCInvokesConcurrent -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m -Dspring.profiles.active=dev -Dorg.jboss.logging.provider=slf4j -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -Djava.net.preferIPv6Addresses=false -Djava.io.tmpdir=/tmp -Dprism.pooldebug=true -Xrunjdwp:server=y,transport=dt_socket,address=8088,suspend=n&quot;CUSTOM_LOG_PATH_OFFLINE=&quot;/home/work/logs&quot;CUSTOM_JVM_ONLINE=&quot; -Xmx4048m -Xms4048m -Xmn1512m -XX:+ExplicitGCInvokesConcurrent -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+PrintGCDetails -XX:+PrintGCDateStamps -Dspring.profiles.active=prod -Dorg.jboss.logging.provider=slf4j&quot;CUSTOM_LOG_PATH_ONLINE=&quot;/home/work/logs&quot;DEFAULT_LOG_PATH=&quot;/home/work/logs&quot;if [ -z $&#123;LOG_PATH&#125; ]; then LOG_PATH=&quot;$&#123;DEFAULT_LOG_PATH&#125;&quot;fiecho $&#123;LOG_PATH&#125;DEFAULT_JVM=&quot; -Xloggc:$LOG_PATH/$WEB_APP.gc.log.`date +%Y%m%d%H%M` -XX:ErrorFile=$LOG_PATH/$WEB_APP.vmerr.log.`date +%Y%m%d%H%M` -XX:HeapDumpPath=$LOG_PATH/$WEB_APP.heaperr.log.`date +%Y%m%d%H%M` -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails -XX:+PrintGCDateStamps&quot;function is_online() &#123; # 得到主机名 HOST_NAME=`hostname` if [[ $&#123;HOST_NAME&#125; =~ &quot;.inf&quot; ]] ; then echo false elif [[ $&#123;HOST_NAME&#125; =~ &quot;.sankuai.com&quot; ]]; then echo true else echo false fi&#125;function init() &#123; echo $&#123;WEB_APP&#125; PID_NUM=$(ps aux |grep &quot;$&#123;WEB_APP&#125;\.jar&quot;|grep -v &quot;grep&quot;|awk &apos;&#123;print $2&#125;&apos;) echo $&#123;PID_NUM&#125; if [ $&#123;PID_NUM&#125; ] ; then echo kill $&#123;WEB_APP&#125;.jar kill $&#123;PID_NUM&#125; echo sleep 10 sleep 10 PID_NUM=$(ps aux |grep &quot;$&#123;WEB_APP&#125;\.jar&quot;|grep -v &quot;grep&quot;|awk &apos;&#123;print $2&#125;&apos;) if [ $&#123;PID_NUM&#125; ] ; then echo kill -9 $&#123;WEB_APP&#125;.jar kill -9 $&#123;PID_NUM&#125; fi else echo $&#123;WEB_APP&#125;.jar not running fi&#125;function run() &#123; echo starting... if [ -d &quot;logs&quot; ]; then echo rm logs rm -rf logs fi # 根据主机名判断是否是线上环境 IS_ONLINE=`is_online` echo &quot;IS_ONLINE:&quot;$&#123;IS_ONLINE&#125; # 环境设置 if [ $&#123;IS_ONLINE&#125; = &quot;true&quot; ]; then CUSTOM_JVM=&quot;$&#123;CUSTOM_JVM_ONLINE&#125; $&#123;DEFAULT_JVM&#125;&quot; # 指定LOG_PATH为线上路径 LOG_PATH=&quot;$&#123;CUSTOM_LOG_PATH_ONLINE&#125;&quot; ln -s $&#123;CUSTOM_LOG_PATH_ONLINE&#125; logs else CUSTOM_JVM=&quot;$&#123;CUSTOM_JVM_OFFLINE&#125; $&#123;JACOCO_ARGS&#125; $&#123;DEFAULT_JVM&#125;&quot; # 指定LOG_PATH为线下路径 LOG_PATH=&quot;$&#123;CUSTOM_LOG_PATH_OFFLINE&#125;&quot; ln -s $&#123;CUSTOM_LOG_PATH_OFFLINE&#125; logs fi exec /home/w/java/default/bin/java $&#123;CUSTOM_JVM&#125; -jar /home/work/$&#123;WEB_APP&#125;.jar &gt; output.log 2&gt;&amp;1 &amp; echo run finished&#125;initrun]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker搭建gitlab ci环境]]></title>
    <url>%2F2018%2F10%2F13%2Fgitlab01%2F</url>
    <content type="text"><![CDATA[背景介绍随着devops的越来越火，CI(Continuous Integration)、CD(continuous Deployment)越来越流行，有规模的公司都会有一套持续集成的环境。比较主流的开源的组件如jenkins。提供github开源项目的CI组件travis。笔者这里介绍的是gitlab ci，gitlab8.0之后提供了自身的CI功能，这使得配置变得简单。 概念介绍 gitlab server：gitlab的基础环境，比如你的代码需要提交到这里，它可以集成ci，运行runner gitlab ci：ci默认是随gitlab-server一起安装的。 gitlab runner：每一个项目要指定自己的任务执行，这个任务相当于runner，当然也可以使用公共的runner。 为什么使用dockerdocker的概念这里不赘述，之所以使用，当然是应为它简单，举个例子，如果你自己安装一个gitlab，你要安装gitlab依赖的redis、postgresql等环境，docker会打包安装好。想想这是一件多么简单的事情。 安装步骤linuxbrew作为mac的用户，homebrew是必不可少的工具，那么像centos的系统有没有类似的工具，这里推荐linuxbrew，使用方式和homebrew一样，官网：http://linuxbrew.sh/ 安装 1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Linuxbrew/install/master/install.sh)&quot; 环境设置 1234test -d ~/.linuxbrew &amp;&amp; PATH=&quot;$HOME/.linuxbrew/bin:$HOME/.linuxbrew/sbin:$PATH&quot;test -d /home/linuxbrew/.linuxbrew &amp;&amp; PATH=&quot;/home/linuxbrew/.linuxbrew/bin:/home/linuxbrew/.linuxbrew/sbin:$PATH&quot;test -r ~/.bash_profile &amp;&amp; echo &quot;export PATH=&apos;$(brew --prefix)/bin:$(brew --prefix)/sbin&apos;&quot;:&apos;&quot;$PATH&quot;&apos; &gt;&gt;~/.bash_profileecho &quot;export PATH=&apos;$(brew --prefix)/bin:$(brew --prefix)/sbin&apos;&quot;:&apos;&quot;$PATH&quot;&apos; &gt;&gt;~/.profile 安装docker就是这么简单！！！等待安装完成就好。 1brew install docker 检查是否成功 1docker version 安装gitlab&amp;gitlab runner安装之前查看image 12docker search gitlabdocker search gitlab-runner 安装 12docker pull gitlabdocker pull gitlab-runner 启动gitlab官网：https://docs.gitlab.com/omnibus/docker/ 123456789sudo docker run --detach \ --hostname 192.168.1.201 \ --publish 44301:443 --publish 8001:80 --publish 2201:22 \ --name gitlab \ --restart always \ --volume /home/w/gitlab/config:/etc/gitlab \ --volume /home/w/gitlab/logs:/var/log/gitlab \ --volume /home/w/gitlab/data:/var/opt/gitlab \ gitlab/gitlab-ce:latest 192.168.1.201是你本机的ip，注意不要写localhost或者127.0.0.1/home/w是你本地映射docker环境的文件，如果不存在会创建。 配置端口映射1vim /home/w/gitlab/config/gitlab.rb 1234external_url &apos;http://192.168.1.201:8001&apos;nginx[&apos;listen_port&apos;] = 80gitlab_rails[&apos;gitlab_ssh_host&apos;] = &apos;192.168.1.201&apos;gitlab_rails[&apos;gitlab_shell_ssh_port&apos;] = 2201 12# (imageId通过docker ps -a查看)docker restart imageid 注册gitlab-runner官网：https://docs.gitlab.com/runner/install/docker.html 1docker run --rm -t -i -v /home/w/gitlab-runner/config:/etc/gitlab-runner --name gitlab-runner gitlab/gitlab-runner register 这里会一步一步提示需要的信息，详情见官网，如果是specific runner 则token在项目下的ci页面内 如果是共享的runner，则token在管理员的runner配置内Admin-Area-&gt; Overview -&gt; Runners也就是可以注册多个runner,name不同即可。 1docker run --rm -t -i -v /home/w/gitlab-runner/config:/etc/gitlab-runner --name gitlab-runner2 gitlab/gitlab-runner register 启动gitlab-runner1234docker run -d --name gitlab-runner --restart always \ -v /home/w/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest 现在可以部署你自己的项目到gitlab了！]]></content>
      <categories>
        <category>devops</category>
      </categories>
      <tags>
        <tag>devops</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[系统中限流的简单实现]]></title>
    <url>%2F2018%2F10%2F12%2Fflowlimit%2F</url>
    <content type="text"><![CDATA[问题引入针对于系统中调用流量较高，但是一些流量可以舍弃的条件下需要限流的方式来减少对服务器的压力，大多服务中间件都会提供限流方案，近期阿里开源了Sentinel：https://github.com/alibaba/Sentinel，有兴趣的同学可以关注下。还有一个简单的限流工具推荐下： https://github.com/wangzheng0822/ratelimiter4j。 限流常用算法令牌桶限流令牌桶是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌，填满了就丢弃令牌，请求是否被处理要看桶中令牌是否足够，当令牌数减为零时则拒绝新的请求。令牌桶允许一定程度突发流量，只要有令牌就可以处理，支持一次拿多个令牌。令牌桶中装的是令牌。 漏桶限流漏桶一个固定容量的漏桶，按照固定常量速率流出请求，流入请求速率任意，当流入的请求数累积到漏桶容量时，则新流入的请求被拒绝。漏桶可以看做是一个具有固定容量、固定流出速率的队列，漏桶限制的是请求的流出速率。漏桶中装的是请求。 计数器限流有时我们还会使用计数器来进行限流，主要用来限制一定时间内的总并发数，比如数据库连接池、线程池、秒杀的并发数；计数器限流只要一定时间内的总请求数超过设定的阀值则进行限流，是一种简单粗暴的总数量限流，而不是平均速率限流。 实现通过信号量简单实现以下漏铜限流的算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class FlowLimit &#123; private final static Semaphore semaphore = new Semaphore(10, true); private final static ExecutorService executorService = new ThreadPoolExecutor(50, 50, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;()); private final static CyclicBarrier cyclicBarrier = new CyclicBarrier(50); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 50; i++) &#123; Task task = new Task(i); executorService.execute(task); &#125; executorService.shutdown(); System.out.println(&quot;availablePermits: &quot; + semaphore.availablePermits()); &#125; private static boolean doExecute(int name) &#123; try &#123; boolean result = semaphore.tryAcquire(50, TimeUnit.MILLISECONDS); if (!result) &#123; System.out.println(name + &quot; :post failure&quot;); return false; &#125; TimeUnit.MILLISECONDS.sleep(2000); System.out.println(name + &quot; :post success&quot;); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return true; &#125; static class Task implements Runnable &#123; private int name; public Task(int name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; cyclicBarrier.await(); &#125; catch (InterruptedException | BrokenBarrierException e) &#123; e.printStackTrace(); &#125; doExecute(name); &#125; &#125;&#125; 通过CyclicBarrier模拟50个并发请求，每个请求的处理时间模拟为2s，限流的大小是10，这样的结果是10个成功，其余40个失败。 顺便说一下模拟并发采用countDownLatch也可以实现，方式如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class FlowLimit &#123; private final static Semaphore semaphore = new Semaphore(10, true); private final static CountDownLatch countDownLatch = new CountDownLatch(1); private final static ExecutorService executorService = new ThreadPoolExecutor(100, 100, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;()); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 50; i++) &#123; Task task = new Task(i); executorService.execute(task); &#125; countDownLatch.countDown(); executorService.shutdown(); TimeUnit.MILLISECONDS.sleep(5000); &#125; private static boolean doExecute(int name) &#123; try &#123; boolean result = semaphore.tryAcquire(50, TimeUnit.MILLISECONDS); if (!result) &#123; System.out.println(name + &quot; :post failure&quot;); return false; &#125; TimeUnit.MILLISECONDS.sleep(2000); System.out.println(name + &quot; :post success&quot;); semaphore.release(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return true; &#125; static class Task implements Runnable &#123; private int name; public Task(int name) &#123; this.name = name; &#125; @Override public void run() &#123; try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; doExecute(name); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud环境搭建]]></title>
    <url>%2F2018%2F10%2F02%2Fspringcloud02%2F</url>
    <content type="text"><![CDATA[问题引入这篇文章的目的是让读者了解如何通过SpringCloud来搭建服务，与Dubbo，Thrift这两款组件作为微服务中间件需要有专门的团队进行扩展维护。SpringCloud作为很火的开源项目，提供了很全面的微服务组件。本篇文章不会详细的描述搭建过程，因为网络上这种文章太多，笔者写不出新颖的东西，不过笔者可以把搭建的思路这这里描述一下。 术语普及首先是注册中心Eureka、Consul，这里需要说明一点，Eureka其实指的事Eureka-Server，它和Consul都是类似ZK的集群。应用服务即业务服务，比如用户模块、支付模块、订单模块等等。这里就是Eureka-Client，当然这里说的服务是指服务提供方即（Provider）。那么服务调用方（Consumer）也相当于Eureka-Client，它调用服务的时候不像Dubbo看成一个Bean，而是通过http服务方式访问，Spring-Cloud提供了一个组件Fegin，可以进行调用。 EurekaServer == Consul == Zookeeper (Cluster) EurekaClient == Provider (Cluster) EurekaClient == Consumer (Cluster) 帮助文档这里推荐一个比较全的简单流程：https://github.com/dyc87112/SpringCloud-Learning当然看Spring-Cloud的官网文档比较好： https://spring.io/guidesSping-Cloud中文文档： https://springcloud.cc/spring-cloud-dalston.html 注意事项SpringCloud的最大问题是版本迭代太快，这就导致一个问题，不同版本的配置可能会不同，比如SpringCloud官网目前能看到Finchley、Edgware Dalston这几个版本，不同版本之间一定会有差异，所以这是一定值得注意的地方。当然除了SpringCloud的版本还要注意SpringBoot的版本，包括1.0+和2.0+的差异。Eureka2.0不再维护，所以注册中心可以选择Consul进行支持。 架构设计最后看一下SpringCloud的架构图。（图片来源于网络）]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud解决consul healthcheck配置问题]]></title>
    <url>%2F2018%2F10%2F01%2Fspringcloud01%2F</url>
    <content type="text"><![CDATA[前言在目前微服务很火爆的情况下，SpringCloud作为各种组件应有尽有并且开源的情况下受到很多公司青睐，这篇文章主要是针对consul作为服务注册中心的配置。Eureka2.0闭源，加上Consul作为ServiceMesh提出理念下的一个新生产物，将来会受到很多青睐。 环境搭建Consul的官网：https://www.consul.io/ consul配置这里采用docker配置一个consul集群，3个server端，1个client端 12345678910111213141516# consul cluster by docker# run the first server node expecting at least two more nodes to form a Consul clusterdocker run -d --name node1 -h node1 progrium/consul -server -bootstrap-expect 3# other two nodes will join the first one using its IP (in Docker network)JOIN_IP=&quot;$(docker inspect -f &apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; node1)&quot;# run second server nodedocker run -d --name node2 -h node2 progrium/consul -server -join $JOIN_IP# run third server nodedocker run -d --name node3 -h node3 progrium/consul -server -join $JOIN_IP# run fourth *client* node, this time exposing Consul ports to the host machine# it&apos;ll be able to communicate with the cluster but will not participate in the consensus quorumdocker run -d -p 8400:8400 -p 8500:8500 -p 8600:53/udp --name node4 -h node4 progrium/consul -join $JOIN_IP SpringCloud服务配置123456789@EnableDiscoveryClient@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; 这个很多读者应该都了解过，不赘述。 这里着重讲一下application.properties的配置 12345678910111213141516171819202122spring.application.name=consul-clientserver.port=9093# consul注册中心的urlspring.cloud.consul.host=localhost# consul注册中心portspring.cloud.consul.port=8500spring.cloud.consul.discovery.enabled=truespring.cloud.consul.discovery.register=truespring.cloud.consul.discovery.prefer-ip-address=truespring.cloud.consul.discovery.register-health-check=truespring.cloud.consul.discovery.hostname=localhost # 健康检测的url，如果不配置，健康检测一定失败spring.cloud.consul.discovery.health-check-path=/health# 健康检测时间间隔spring.cloud.consul.discovery.health-check-interval=10s# springboot2.0+加入下面配置management.endpoints.web.exposure.include=*# springboot2.0+health路径如下spring.cloud.consul.discovery.health-check-path=/actuator/health 启动之后访问http://localhost:8500 总结 这个配置选项是自己试出来的，官网目前没有好的说明。 spring-cloud-consul这个项目目前还不完善，Issues还很多。spring-cloud-consul链接]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何解决spring中抽象类无法注入]]></title>
    <url>%2F2018%2F09%2F30%2Fspringboot01%2F</url>
    <content type="text"><![CDATA[问题引入首先明确一个问题：抽象类不能生成实例对象，spring无法注入。 原因：spring的原理是启动服务器时读取配置文件，取得类名后利用反射机制在spring上下文中生成一个单例的对象，由spring注入属性并维护此对象的状态，抽象类在反射生成对象时就已经失败了，后面的不会进行 如何解决方案1限于springboot方式启动，我们编写一个SpringBeanLoader的类，在应用启动时加载org.springframework.context.ApplicationContext，对外通过ApplicationContext提供获取bean的方法，代码如下： 应用启动时设置applicationContext 123456789public class Application &#123; public static void main(String[] args) &#123; ApplicationContext applicationContext = SpringApplication.run(Application.class, args); SpringBeanLoader.setApplicationContext(applicationContext); &#125;&#125; SpringBeanLoader结构 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class SpringBeanLoader &#123; private static ApplicationContext applicationContext; /** * 获取SpringApplicationContext * * @return ApplicationContext */ private static ApplicationContext getApplicationContext() &#123; return applicationContext; &#125; /** * 设置SpringApplicationContext * * @param applicationContext */ public static void setApplicationContext(ApplicationContext applicationContext) &#123; SpringBeanLoader.applicationContext = applicationContext; &#125; /** * 获取Spring中注册的Bean * * @param beanClass * @param beanId * @return */ public static &lt;T&gt; T getSpringBean(String beanId, Class&lt;T&gt; beanClass) &#123; return getApplicationContext().getBean(beanId, beanClass); &#125; /** * 获取Spring中注册的Bean * * @param beanClass * @return */ public static &lt;T&gt; T getSpringBean(Class&lt;T&gt; beanClass) &#123; return getApplicationContext().getBean(beanClass); &#125;&#125; 下面测试一下定义一个HelloService和HelloServiceImpl 123public interface HelloService &#123; String echo(String str);&#125; 1234567@Componentpublic class HelloServiceImpl implements HelloService &#123; @Override public String echo(String str) &#123; return str; &#125;&#125; 抽象类 12345678public abstract class AbstractService &#123; public String testSpringIoc() &#123; HelloService helloService = SpringBeanLoader.getSpringBean(HelloService.class); return helloService.echo(&quot;test&quot;); &#125;&#125; 调用类 1234567public class TestService extends AbstractService&#123; public String test()&#123; return testSpringIoc(); &#125;&#125; 编写测试类 123456789101112131415@RunWith(SpringJUnit4ClassRunner.class)public class AbstractServiceTest &#123; @Before public void init() &#123; ApplicationContext applicationContext = new SpringApplicationBuilder(Application.class).web(true).run(); SpringBeanLoader.setApplicationContext(applicationContext); &#125; @Test public void test_Ioc() &#123; TestService testService = new TestService(); System.out.println(testService.testSpringIoc()); &#125;&#125; 输出结果：1test 方案2通过构造函数将org.springframework.context.ApplicationContext注入到抽象类中，编辑一个ApplicationContext的持有类：ApplicationContextHolder 12345678910111213141516171819202122232425262728293031@Componentpublic class ApplicationContextHolder implements ApplicationContextAware &#123; private ApplicationContext applicationContext; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125; /** * 获取Spring中注册的Bean * * @param beanClass * @param beanId * @return */ public &lt;T&gt; T getSpringBean(String beanId, Class&lt;T&gt; beanClass) &#123; return applicationContext.getBean(beanId, beanClass); &#125; /** * 获取Spring中注册的Bean * * @param beanClass * @return */ public &lt;T&gt; T getSpringBean(Class&lt;T&gt; beanClass) &#123; return applicationContext.getBean(beanClass); &#125;&#125; 测试： 抽象类： 1234567891011121314public abstract class AbstractService2 &#123; private final ApplicationContextHolder applicationContextHolder; public AbstractService2(ApplicationContextHolder applicationContextHolder) &#123; this.applicationContextHolder = applicationContextHolder; &#125; public String testSpringIoc() &#123; HelloService helloService = applicationContextHolder.getSpringBean(HelloService.class); return helloService.echo(&quot;test&quot;); &#125;&#125; 调用类： 12345678910public class TestService2 extends AbstractService2&#123; public TestService2(ApplicationContextHolder applicationContextHolder) &#123; super(applicationContextHolder); &#125; public String test()&#123; return testSpringIoc(); &#125;&#125; 测试类： 1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = Application.class)public class TestService2Test &#123; @Resource private ApplicationContextHolder applicationContextHolder; @Test public void test_ioc()&#123; TestService2 testService2 = new TestService2(applicationContextHolder); System.out.println(testService2.test()); &#125;&#125; 输出:1test 总结 方案1仅适用于引入springboot的项目，方式比较简单。 方案2使用与springboot项目或通过其他容器加载的项目，方式相比方案1来说复杂一下，需要提供调用方的构造器。 笔者推荐在springboot项目下选择方案1.]]></content>
      <categories>
        <category>Springboot</category>
      </categories>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo交换层和传输层源码心得]]></title>
    <url>%2F2018%2F08%2F22%2Fdubbo1%2F</url>
    <content type="text"><![CDATA[dubbo概览 以下分层结构内容来源于网络 服务接口层（Service）该层是与实际业务逻辑相关的，根据服务提供方和服务消费方的业务设计对应的接口和实现。配置层（Config）：对外配置接口，以ServiceConfig和ReferenceConfig为中心，可以直接new配置类，也可以通过spring解析配置生成配置类。 服务代理层（Proxy）服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。 服务注册层（Registry）封装服务地址的注册与发现，以服务URL为中心，扩展接口为RegistryFactory、Registry和RegistryService。可能没有服务注册中心，此时服务提供方直接暴露服务。 集群层（Cluster）封装多个提供者的路由及负载均衡，并桥接注册中心，以Invoker为中心，扩展接口为Cluster、Directory、Router和LoadBalance。将多个服务提供方组合为一个服务提供方，实现对服务消费方来透明，只需要与一个服务提供方进行交互。监控层（Monitor）：RPC调用次数和调用时间监控，以Statistics为中心，扩展接口为MonitorFactory、Monitor和MonitorService。 远程调用层（Protocol）封将RPC调用，以Invocation和Result为中心，扩展接口为Protocol、Invoker和Exporter。Protocol是服务域，它是Invoker暴露和引用的主功能入口，它负责Invoker的生命周期管理。Invoker是实体域，它是Dubbo的核心模型，其它模型都向它靠扰，或转换成它，它代表一个可执行体，可向它发起invoke调用，它有可能是一个本地的实现，也可能是一个远程的实现，也可能一个集群实现。 信息交换层（Exchange）封装请求响应模式，同步转异步，以Request和Response为中心，扩展接口为Exchanger、ExchangeChannel、ExchangeClient和ExchangeServer。 网络传输层（Transport）抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel、Transporter、Client、Server和Codec。 数据序列化层（Serialize）可复用的一些工具，扩展接口为Serialization、 ObjectInput、ObjectOutput和ThreadPool dubbo分析dubbo的交互层正常来讲应该是不同client端和Server端通路的维护，也就是netty中channel的维护，正常来说一个client和一个server之间相同ip和port可以有多个channel的，但是dubbo在实现知识允许一个ip:port只能维护一个通路，维护多个可能在传输效率上会有提升，但是如何保证字节传输时用相同的channel，以及rpc调用顺序如何保证是一个难点。 网络传输层&amp;信息交换层dubbo如何维护连接通路呢？首先需要知道它采用了SPI的扩展方式，所以提供了Transporter接口，实现了各种扩展，比如netty，mian，grizzly等。默认采用netty方式。 12345678910111213141516171819202122232425262728@SPI(&quot;netty&quot;)public interface Transporter &#123; /** * Bind a server. * * @param url server url * @param handler * @return server * @throws RemotingException * @see org.apache.dubbo.remoting.Transporters#bind(URL, Receiver, ChannelHandler) */ @Adaptive(&#123;Constants.SERVER_KEY, Constants.TRANSPORTER_KEY&#125;) Server bind(URL url, ChannelHandler handler) throws RemotingException; /** * Connect to a server. * * @param url server url * @param handler * @return client * @throws RemotingException * @see org.apache.dubbo.remoting.Transporters#connect(URL, Receiver, ChannelListener) */ @Adaptive(&#123;Constants.CLIENT_KEY, Constants.TRANSPORTER_KEY&#125;) Client connect(URL url, ChannelHandler handler) throws RemotingException;&#125; dubbo捐赠给apache后增加了对netty4的支持，由之前的NettyHandler改为NettyClientHandler和NettyServerHandler。在这两个Handler中会发现他们同时维护一个NettyChannel的类: 123final class NettyChannel extends AbstractChannel &#123; private static final ConcurrentMap&lt;Channel, NettyChannel&gt; channelMap = new ConcurrentHashMap&lt;Channel, NettyChannel&gt;();&#125; 12345public abstract class AbstractChannel extends AbstractPeer implements Channel &#123; public AbstractChannel(URL url, ChannelHandler handler) &#123; super(url, handler); &#125;&#125; 这个类是netty原生channel和dubbo封装的nettyChannel的映射。NettyChannel中包含了Url和ChannelHander，通过装饰者模式层层封装。读源码时很痛苦的是dubbo的send实现在哪？其实就在nettychannel中。 12345678910111213141516171819202122232425@Override public void send(Object message, boolean sent) throws RemotingException &#123; super.send(message, sent); boolean success = true; int timeout = 0; try &#123; ChannelFuture future = channel.writeAndFlush(message); if (sent) &#123; timeout = getUrl().getPositiveParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT); success = future.await(timeout); &#125; Throwable cause = future.cause(); if (cause != null) &#123; throw cause; &#125; &#125; catch (Throwable e) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;, cause: &quot; + e.getMessage(), e); &#125; if (!success) &#123; throw new RemotingException(this, &quot;Failed to send message &quot; + message + &quot; to &quot; + getRemoteAddress() + &quot;in timeout(&quot; + timeout + &quot;ms) limit&quot;); &#125; &#125; NettyChannel的send方法具体的调用如下：dubbo中client的请求功能的实现其实调用的是NettyChannel的send方法，但是谁调用了这个send?NettyClient的抽象类AbstractClient实现了send(Object message,boolean sent)先通过getChannel()获取到channel，这个channel是在dubbo包下的，再调用channel.send()方法，其中getChannel()是AbstractClient是一个抽象方法它的实现实在NettyClient中完成的，也就是NettyChannel中io.netty.channel.channel。 这里从网上找了一张很好的图诠释了dubbo的通信过程：]]></content>
      <categories>
        <category>rpc</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty学习]]></title>
    <url>%2F2018%2F08%2F05%2Fnetty1%2F</url>
    <content type="text"><![CDATA[Channel一个到实体的开放连接，如读操作和写操作。可以看作是出站和入站的载体。 source code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119public interface Channel extends AttributeMap, ChannelOutboundInvoker, Comparable&lt;Channel&gt; &#123; /** * Returns the globally unique identifier of this &#123;@link Channel&#125;. */ ChannelId id(); /** * Return the &#123;@link EventLoop&#125; this &#123;@link Channel&#125; was registered to. */ EventLoop eventLoop(); /** * Returns the parent of this channel. * * @return the parent channel. * &#123;@code null&#125; if this channel does not have a parent channel. */ Channel parent(); /** * Returns the configuration of this channel. */ ChannelConfig config(); /** * Returns &#123;@code true&#125; if the &#123;@link Channel&#125; is open and may get active later */ boolean isOpen(); /** * Returns &#123;@code true&#125; if the &#123;@link Channel&#125; is registered with an &#123;@link EventLoop&#125;. */ boolean isRegistered(); /** * Return &#123;@code true&#125; if the &#123;@link Channel&#125; is active and so connected. */ boolean isActive(); /** * Return the &#123;@link ChannelMetadata&#125; of the &#123;@link Channel&#125; which describe the nature of the &#123;@link Channel&#125;. */ ChannelMetadata metadata(); /** * Returns the local address where this channel is bound to. The returned * &#123;@link SocketAddress&#125; is supposed to be down-cast into more concrete * type such as &#123;@link InetSocketAddress&#125; to retrieve the detailed * information. * * @return the local address of this channel. * &#123;@code null&#125; if this channel is not bound. */ SocketAddress localAddress(); /** * Returns the remote address where this channel is connected to. The * returned &#123;@link SocketAddress&#125; is supposed to be down-cast into more * concrete type such as &#123;@link InetSocketAddress&#125; to retrieve the detailed * information. * * @return the remote address of this channel. * &#123;@code null&#125; if this channel is not connected. * If this channel is not connected but it can receive messages * from arbitrary remote addresses (e.g. &#123;@link DatagramChannel&#125;, * use &#123;@link DatagramPacket#recipient()&#125; to determine * the origination of the received message as this method will * return &#123;@code null&#125;. */ SocketAddress remoteAddress(); /** * Returns the &#123;@link ChannelFuture&#125; which will be notified when this * channel is closed. This method always returns the same future instance. */ ChannelFuture closeFuture(); /** * Returns &#123;@code true&#125; if and only if the I/O thread will perform the * requested write operation immediately. Any write requests made when * this method returns &#123;@code false&#125; are queued until the I/O thread is * ready to process the queued write requests. */ boolean isWritable(); /** * Get how many bytes can be written until &#123;@link #isWritable()&#125; returns &#123;@code false&#125;. * This quantity will always be non-negative. If &#123;@link #isWritable()&#125; is &#123;@code false&#125; then 0. */ long bytesBeforeUnwritable(); /** * Get how many bytes must be drained from underlying buffers until &#123;@link #isWritable()&#125; returns &#123;@code true&#125;. * This quantity will always be non-negative. If &#123;@link #isWritable()&#125; is &#123;@code true&#125; then 0. */ long bytesBeforeWritable(); /** * Returns an &lt;em&gt;internal-use-only&lt;/em&gt; object that provides unsafe operations. */ Unsafe unsafe(); /** * Return the assigned &#123;@link ChannelPipeline&#125;. */ ChannelPipeline pipeline(); /** * Return the assigned &#123;@link ByteBufAllocator&#125; which will be used to allocate &#123;@link ByteBuf&#125;s. */ ByteBufAllocator alloc(); @Override Channel read(); @Override Channel flush();&#125; 回调一个回调可以理解为一个方法 demo123456789public class ConnectHandler extends ChannelInboundHandlerAdapter &#123; @Override //当一个新的连接已经被建立时，channelActive(ChannelHandlerContext)将会被调用 public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println( &quot;Client &quot; + ctx.channel().remoteAddress() + &quot; connected&quot;); &#125;&#125; Futuresource code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface ChannelFuture extends Future&lt;Void&gt; &#123; /** * Returns a channel where the I/O operation associated with this * future takes place. */ Channel channel(); @Override ChannelFuture addListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture addListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture removeListener(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt; listener); @Override ChannelFuture removeListeners(GenericFutureListener&lt;? extends Future&lt;? super Void&gt;&gt;... listeners); @Override ChannelFuture sync() throws InterruptedException; @Override ChannelFuture syncUninterruptibly(); @Override ChannelFuture await() throws InterruptedException; @Override ChannelFuture awaitUninterruptibly(); /** * Returns &#123;@code true&#125; if this &#123;@link ChannelFuture&#125; is a void future and so not allow to call any of the * following methods: * &lt;ul&gt; * &lt;li&gt;&#123;@link #addListener(GenericFutureListener)&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #addListeners(GenericFutureListener[])&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #await()&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #await(long, TimeUnit)&#125; ()&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #await(long)&#125; ()&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #awaitUninterruptibly()&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #sync()&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link #syncUninterruptibly()&#125;&lt;/li&gt; * &lt;/ul&gt; */ boolean isVoid();&#125; demo123456789101112131415public static void addingChannelFutureListener()&#123; Channel channel = CHANNEL_FROM_SOMEWHERE; // get reference to pipeline; ByteBuf someMessage = SOME_MSG_FROM_SOMEWHERE; // get reference to pipeline; //... io.netty.channel.ChannelFuture future = channel.write(someMessage); future.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(io.netty.channel.ChannelFuture f) &#123; if (!f.isSuccess()) &#123; f.cause().printStackTrace(); f.channel().close(); &#125; &#125; &#125;); &#125; 事件和ChaneelHandler入站事件 连接已被激活或失活 数据读取 用户事件 错误事件 出站事件 打开或关闭远程节点的连接 将数据写到或者冲刷到套接字 每个事件都被分配给ChannelHandler类中某个用户实现的方法。]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ribbon负载均衡]]></title>
    <url>%2F2018%2F06%2F11%2Floadbalance01%2F</url>
    <content type="text"><![CDATA[负载均衡 第一种是独立的进程单元，通过负载均衡策略将请求转发到不同的执行单元上，例如nginx 第二种是将负载均衡逻辑封装到服务的消费者上，消费者客户端维护了一个服务提供者的信息列表，通过负载均衡策略分摊给不同的服务提供者 Ribbon负载均衡策略 BestAvailableRule 选择最小请求数 ClientConfigEnabledRoundRobinRule 轮询 RandomRule 随机选择一个Server RoundRobinRule 轮询选择server RetryRule 根据轮询的方式重试 WeightedResponseTimeRule 根据响应时间去分配一个weight，weight越低，被选择的可能性越低 ZoneAvoidanceRule 根据server的zone区域和可用性来轮徐选择 Ribbon负载均衡方式Ribbon采用第二种，如何实现？服务消费客户端从提供者拉去信息列表，缓存到本地，并且每10秒（源码）去ping一下服务端，如果ping通，不拉取，反之则重新拉取 源码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * Class that contains the mechanism to &quot;ping&quot; all the instances * * @author stonse * */class Pinger &#123; private final IPingStrategy pingerStrategy; public Pinger(IPingStrategy pingerStrategy) &#123; this.pingerStrategy = pingerStrategy; &#125; public void runPinger() throws Exception &#123; if (!pingInProgress.compareAndSet(false, true)) &#123; return; // Ping in progress - nothing to do &#125; // we are &quot;in&quot; - we get to Ping Server[] allServers = null; boolean[] results = null; Lock allLock = null; Lock upLock = null; try &#123; /* * The readLock should be free unless an addServer operation is * going on... */ allLock = allServerLock.readLock(); allLock.lock(); allServers = allServerList.toArray(new Server[allServerList.size()]); allLock.unlock(); int numCandidates = allServers.length; results = pingerStrategy.pingServers(ping, allServers); final List&lt;Server&gt; newUpList = new ArrayList&lt;Server&gt;(); final List&lt;Server&gt; changedServers = new ArrayList&lt;Server&gt;(); for (int i = 0; i &lt; numCandidates; i++) &#123; boolean isAlive = results[i]; Server svr = allServers[i]; boolean oldIsAlive = svr.isAlive(); svr.setAlive(isAlive); if (oldIsAlive != isAlive) &#123; changedServers.add(svr); logger.debug(&quot;LoadBalancer [&#123;&#125;]: Server [&#123;&#125;] status changed to &#123;&#125;&quot;, name, svr.getId(), (isAlive ? &quot;ALIVE&quot; : &quot;DEAD&quot;)); &#125; if (isAlive) &#123; newUpList.add(svr); &#125; &#125; upLock = upServerLock.writeLock(); upLock.lock(); upServerList = newUpList; upLock.unlock(); notifyServerStatusChangeListener(changedServers); &#125; finally &#123; pingInProgress.set(false); &#125; &#125;&#125;]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模拟spring ioc]]></title>
    <url>%2F2018%2F05%2F25%2Fioc1%2F</url>
    <content type="text"><![CDATA[属性文件工具类如何从配置文件中获取我们定义的参数 12345678910111213141516171819202122232425262728293031public final class PropsUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(PropsUtil.class); /** * 加载属性文件 */ public static Properties loadProps(String fileName) &#123; Properties props = null; InputStream is = null; try &#123; is = ClassUtil.getClassLoader().getResourceAsStream(fileName); if (is == null) &#123; throw new FileNotFoundException(fileName + &quot; file is not found&quot;); &#125; props = new Properties(); props.load(is); &#125; catch (IOException e) &#123; LOGGER.error(&quot;load properties file failure&quot;, e); &#125; finally &#123; if (is != null) &#123; try &#123; is.close(); &#125; catch (IOException e) &#123; LOGGER.error(&quot;close input stream failure&quot;, e); &#125; &#125; &#125; return props; &#125;&#125; 配置中心1234567891011121314public interface ConfigConstant &#123; String CONFIG_FILE = &quot;smart.properties&quot;; String JDBC_DRIVER = &quot;smart.framework.jdbc.driver&quot;; String JDBC_URL = &quot;smart.framework.jdbc.url&quot;; String JDBC_USERNAME = &quot;smart.framework.jdbc.username&quot;; String JDBC_PASSWORD = &quot;smart.framework.jdbc.password&quot;; String APP_BASE_PACKAGE = &quot;smart.framework.app.base_package&quot;; String APP_JSP_PATH = &quot;smart.framework.app.jsp_path&quot;; String APP_ASSET_PATH = &quot;smart.framework.app.asset_path&quot;; String APP_UPLOAD_LIMIT = &quot;smart.framework.app.upload_limit&quot;;&#125; 我们提供一个配置中心的助手类，用来加载上面的配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public final class ConfigHelper &#123; private static final Properties CONFIG_PROPS = PropsUtil.loadProps(ConfigConstant.CONFIG_FILE); /** * 获取 JDBC 驱动 */ public static String getJdbcDriver() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.JDBC_DRIVER); &#125; /** * 获取 JDBC URL */ public static String getJdbcUrl() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.JDBC_URL); &#125; /** * 获取 JDBC 用户名 */ public static String getJdbcUsername() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.JDBC_USERNAME); &#125; /** * 获取 JDBC 密码 */ public static String getJdbcPassword() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.JDBC_PASSWORD); &#125; /** * 获取应用基础包名 */ public static String getAppBasePackage() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.APP_BASE_PACKAGE); &#125; /** * 获取应用 JSP 路径 */ public static String getAppJspPath() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.APP_JSP_PATH, &quot;/WEB-INF/view/&quot;); &#125; /** * 获取应用静态资源路径 */ public static String getAppAssetPath() &#123; return PropsUtil.getString(CONFIG_PROPS, ConfigConstant.APP_ASSET_PATH, &quot;/asset/&quot;); &#125; /** * 获取应用文件上传限制 */ public static int getAppUploadLimit() &#123; return PropsUtil.getInt(CONFIG_PROPS, ConfigConstant.APP_UPLOAD_LIMIT, 10); &#125; /** * 根据属性名获取 String 类型的属性值 */ public static String getString(String key) &#123; return PropsUtil.getString(CONFIG_PROPS, key); &#125; /** * 根据属性名获取 int 类型的属性值 */ public static int getInt(String key) &#123; return PropsUtil.getInt(CONFIG_PROPS, key); &#125; /** * 根据属性名获取 boolean 类型的属性值 */ public static boolean getBoolean(String key) &#123; return PropsUtil.getBoolean(CONFIG_PROPS, key); &#125;&#125; 类加载器获取类加载器，加载类以及扫描包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public final class ClassUtil &#123; private static final Logger LOGGER = LoggerFactory.getLogger(ClassUtil.class); /** * 获取类加载器 */ public static ClassLoader getClassLoader() &#123; return Thread.currentThread().getContextClassLoader(); &#125; /** * 加载类 */ public static Class&lt;?&gt; loadClass(String className, boolean isInitialized) &#123; Class&lt;?&gt; cls; try &#123; cls = Class.forName(className, isInitialized, getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; LOGGER.error(&quot;load class failure&quot;, e); throw new RuntimeException(e); &#125; return cls; &#125; /** * 加载类（默认将初始化类） */ public static Class&lt;?&gt; loadClass(String className) &#123; return loadClass(className, true); &#125; /** * 获取指定包名下的所有类 */ public static Set&lt;Class&lt;?&gt;&gt; getClassSet(String packageName) &#123; Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); try &#123; Enumeration&lt;URL&gt; urls = getClassLoader().getResources(packageName.replace(&quot;.&quot;, &quot;/&quot;)); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); if (url != null) &#123; String protocol = url.getProtocol(); if (protocol.equals(&quot;file&quot;)) &#123; String packagePath = url.getPath().replaceAll(&quot;%20&quot;, &quot; &quot;); addClass(classSet, packagePath, packageName); &#125; else if (protocol.equals(&quot;jar&quot;)) &#123; JarURLConnection jarURLConnection = (JarURLConnection) url.openConnection(); if (jarURLConnection != null) &#123; JarFile jarFile = jarURLConnection.getJarFile(); if (jarFile != null) &#123; Enumeration&lt;JarEntry&gt; jarEntries = jarFile.entries(); while (jarEntries.hasMoreElements()) &#123; JarEntry jarEntry = jarEntries.nextElement(); String jarEntryName = jarEntry.getName(); if (jarEntryName.endsWith(&quot;.class&quot;)) &#123; String className = jarEntryName.substring(0, jarEntryName.lastIndexOf(&quot;.&quot;)).replaceAll(&quot;/&quot;, &quot;.&quot;); doAddClass(classSet, className); &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; catch (Exception e) &#123; LOGGER.error(&quot;get class set failure&quot;, e); throw new RuntimeException(e); &#125; return classSet; &#125; private static void addClass(Set&lt;Class&lt;?&gt;&gt; classSet, String packagePath, String packageName) &#123; File[] files = new File(packagePath).listFiles(new FileFilter() &#123; public boolean accept(File file) &#123; return (file.isFile() &amp;&amp; file.getName().endsWith(&quot;.class&quot;)) || file.isDirectory(); &#125; &#125;); for (File file : files) &#123; String fileName = file.getName(); if (file.isFile()) &#123; String className = fileName.substring(0, fileName.lastIndexOf(&quot;.&quot;)); if (StringUtil.isNotEmpty(packageName)) &#123; className = packageName + &quot;.&quot; + className; &#125; doAddClass(classSet, className); &#125; else &#123; String subPackagePath = fileName; if (StringUtil.isNotEmpty(packagePath)) &#123; subPackagePath = packagePath + &quot;/&quot; + subPackagePath; &#125; String subPackageName = fileName; if (StringUtil.isNotEmpty(packageName)) &#123; subPackageName = packageName + &quot;.&quot; + subPackageName; &#125; addClass(classSet, subPackagePath, subPackageName); &#125; &#125; &#125; private static void doAddClass(Set&lt;Class&lt;?&gt;&gt; classSet, String className) &#123; Class&lt;?&gt; cls = loadClass(className, false); classSet.add(cls); &#125;&#125; 定义注解123456789101112131415161718192021222324252627282930313233343536/** * 控制器注解 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface Controller &#123;&#125;/** * 服务类注解 */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)public @interface Service &#123;&#125;/** * Action 方法注解 */@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface Action &#123; /** * 请求类型与路径 */ String value();&#125;/** * 依赖注入注解 */@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)public @interface Inject &#123;&#125; 类操作管理获取包下所有的Bean类，获取控制层、服务层等所有类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public final class ClassHelper &#123; /** * 定义类集合（用于存放所加载的类） */ private static final Set&lt;Class&lt;?&gt;&gt; CLASS_SET; static &#123; String basePackage = ConfigHelper.getAppBasePackage(); CLASS_SET = ClassUtil.getClassSet(basePackage); &#125; /** * 获取应用包名下的所有类 */ public static Set&lt;Class&lt;?&gt;&gt; getClassSet() &#123; return CLASS_SET; &#125; /** * 获取应用包名下所有 Service 类 */ public static Set&lt;Class&lt;?&gt;&gt; getServiceClassSet() &#123; Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) &#123; if (cls.isAnnotationPresent(Service.class)) &#123; classSet.add(cls); &#125; &#125; return classSet; &#125; /** * 获取应用包名下所有 Controller 类 */ public static Set&lt;Class&lt;?&gt;&gt; getControllerClassSet() &#123; Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) &#123; if (cls.isAnnotationPresent(Controller.class)) &#123; classSet.add(cls); &#125; &#125; return classSet; &#125; /** * 获取应用包名下所有 Bean 类（包括：Service、Controller 等） */ public static Set&lt;Class&lt;?&gt;&gt; getBeanClassSet() &#123; Set&lt;Class&lt;?&gt;&gt; beanClassSet = new HashSet&lt;Class&lt;?&gt;&gt;(); beanClassSet.addAll(getServiceClassSet()); beanClassSet.addAll(getControllerClassSet()); return beanClassSet; &#125; /** * 获取应用包名下某父类（或接口）的所有子类（或实现类） */ public static Set&lt;Class&lt;?&gt;&gt; getClassSetBySuper(Class&lt;?&gt; superClass) &#123; Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) &#123; if (superClass.isAssignableFrom(cls) &amp;&amp; !superClass.equals(cls)) &#123; classSet.add(cls); &#125; &#125; return classSet; &#125; /** * 获取应用包名下带有某注解的所有类 */ public static Set&lt;Class&lt;?&gt;&gt; getClassSetByAnnotation(Class&lt;? extends Annotation&gt; annotationClass) &#123; Set&lt;Class&lt;?&gt;&gt; classSet = new HashSet&lt;Class&lt;?&gt;&gt;(); for (Class&lt;?&gt; cls : CLASS_SET) &#123; if (cls.isAnnotationPresent(annotationClass)) &#123; classSet.add(cls); &#125; &#125; return classSet; &#125;&#125; Bean管理维护一个Map，key是class，value是class对应的实例 12345678910111213141516171819202122232425262728293031323334353637public final class BeanHelper &#123; private static final Map&lt;Class&lt;?&gt;, Object&gt; BEAN_MAP = new HashMap&lt;Class&lt;?&gt;, Object&gt;(); static &#123; Set&lt;Class&lt;?&gt;&gt; beanClassSet = ClassHelper.getBeanClassSet(); for (Class&lt;?&gt; beanClass : beanClassSet) &#123; Object obj = ReflectionUtil.newInstance(beanClass); BEAN_MAP.put(beanClass, obj); &#125; &#125; /** * 获取 Bean 映射 */ public static Map&lt;Class&lt;?&gt;, Object&gt; getBeanMap() &#123; return BEAN_MAP; &#125; /** * 获取 Bean 实例 */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T getBean(Class&lt;T&gt; cls) &#123; if (!BEAN_MAP.containsKey(cls)) &#123; throw new RuntimeException(&quot;can not get bean by class: &quot; + cls); &#125; return (T) BEAN_MAP.get(cls); &#125; /** * 设置 Bean 实例 */ public static void setBean(Class&lt;?&gt; cls, Object obj) &#123; BEAN_MAP.put(cls, obj); &#125;&#125; 依赖注入对于控制器Controller，可以将服务层Service注入其中 1234567891011121314151617181920212223public final class IocHelper &#123; static &#123; Map&lt;Class&lt;?&gt;, Object&gt; beanMap = BeanHelper.getBeanMap(); if (CollectionUtil.isNotEmpty(beanMap)) &#123; for (Map.Entry&lt;Class&lt;?&gt;, Object&gt; beanEntry : beanMap.entrySet()) &#123; Class&lt;?&gt; beanClass = beanEntry.getKey(); Object beanInstance = beanEntry.getValue(); Field[] beanFields = beanClass.getDeclaredFields(); if (ArrayUtil.isNotEmpty(beanFields)) &#123; for (Field beanField : beanFields) &#123; if (beanField.isAnnotationPresent(Inject.class)) &#123; Class&lt;?&gt; beanFieldClass = beanField.getType(); Object beanFieldInstance = beanMap.get(beanFieldClass); if (beanFieldInstance != null) &#123; ReflectionUtil.setField(beanInstance, beanField, beanFieldInstance); &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; 控制器管理维护一个Map，key为请求，value为对应的处理器123456789101112131415/** * 封装请求信息 */public class Request &#123; /** * 请求方法 */ private String requestMethod; /** * 请求路径 */ private String requestPath;&#125; 123456789101112131415/** * 封装 Action 信息 */public class Handler &#123; /** * Controller 类 */ private Class&lt;?&gt; controllerClass; /** * Action 方法 */ private Method actionMethod;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 控制器助手类 */public final class ControllerHelper &#123; private static final Map&lt;Request, Handler&gt; ACTION_MAP = new HashMap&lt;Request, Handler&gt;(); static &#123; Set&lt;Class&lt;?&gt;&gt; controllerClassSet = ClassHelper.getControllerClassSet(); if (CollectionUtil.isNotEmpty(controllerClassSet)) &#123; for (Class&lt;?&gt; controllerClass : controllerClassSet) &#123; Method[] methods = controllerClass.getDeclaredMethods(); if (ArrayUtil.isNotEmpty(methods)) &#123; for (Method method : methods) &#123; if (method.isAnnotationPresent(Action.class)) &#123; Action action = method.getAnnotation(Action.class); String mapping = action.value(); if (mapping.matches(&quot;\\w+:/\\w*&quot;)) &#123; String[] array = mapping.split(&quot;:&quot;); if (ArrayUtil.isNotEmpty(array) &amp;&amp; array.length == 2) &#123; String requestMethod = array[0]; String requestPath = array[1]; Request request = new Request(requestMethod, requestPath); Handler handler = new Handler(controllerClass, method); ACTION_MAP.put(request, handler); &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; /** * 获取 Handler */ public static Handler getHandler(String requestMethod, String requestPath) &#123; Request request = new Request(requestMethod, requestPath); return ACTION_MAP.get(request); &#125;&#125; 核心类-请求转发器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@WebServlet(urlPatterns = &quot;/*&quot;, loadOnStartup = 0)public class DispatcherServlet extends HttpServlet &#123; @Override public void init(ServletConfig servletConfig) throws ServletException &#123; HelperLoader.init(); ServletContext servletContext = servletConfig.getServletContext(); registerServlet(servletContext); UploadHelper.init(servletContext); &#125; private void registerServlet(ServletContext servletContext) &#123; ServletRegistration jspServlet = servletContext.getServletRegistration(&quot;jsp&quot;); jspServlet.addMapping(&quot;/index.jsp&quot;); jspServlet.addMapping(ConfigHelper.getAppJspPath() + &quot;*&quot;); ServletRegistration defaultServlet = servletContext.getServletRegistration(&quot;default&quot;); defaultServlet.addMapping(&quot;/favicon.ico&quot;); defaultServlet.addMapping(ConfigHelper.getAppAssetPath() + &quot;*&quot;); &#125; @Override public void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; ServletHelper.init(request, response); try &#123; String requestMethod = request.getMethod().toLowerCase(); String requestPath = request.getPathInfo(); Handler handler = ControllerHelper.getHandler(requestMethod, requestPath); if (handler != null) &#123; Class&lt;?&gt; controllerClass = handler.getControllerClass(); Object controllerBean = BeanHelper.getBean(controllerClass); Param param; if (UploadHelper.isMultipart(request)) &#123; param = UploadHelper.createParam(request); &#125; else &#123; param = RequestHelper.createParam(request); &#125; Object result; Method actionMethod = handler.getActionMethod(); if (param.isEmpty()) &#123; result = ReflectionUtil.invokeMethod(controllerBean, actionMethod); &#125; else &#123; result = ReflectionUtil.invokeMethod(controllerBean, actionMethod, param); &#125; if (result instanceof View) &#123; handleViewResult((View) result, request, response); &#125; else if (result instanceof Data) &#123; handleDataResult((Data) result, response); &#125; &#125; &#125; finally &#123; ServletHelper.destroy(); &#125; &#125; private void handleViewResult(View view, HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; String path = view.getPath(); if (StringUtil.isNotEmpty(path)) &#123; if (path.startsWith(&quot;/&quot;)) &#123; response.sendRedirect(request.getContextPath() + path); &#125; else &#123; Map&lt;String, Object&gt; model = view.getModel(); for (Map.Entry&lt;String, Object&gt; entry : model.entrySet()) &#123; request.setAttribute(entry.getKey(), entry.getValue()); &#125; request.getRequestDispatcher(ConfigHelper.getAppJspPath() + path).forward(request, response); &#125; &#125; &#125; private void handleDataResult(Data data, HttpServletResponse response) throws IOException &#123; Object model = data.getModel(); if (model != null) &#123; response.setContentType(&quot;application/json&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;); PrintWriter writer = response.getWriter(); String json = JsonUtil.toJson(model); writer.write(json); writer.flush(); writer.close(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建一个简单的Java MVC框架]]></title>
    <url>%2F2018%2F04%2F26%2Fmvcframework%2F</url>
    <content type="text"><![CDATA[路由设计路由对象1234567891011121314151617public class Route &#123; /** * 路由path */ private String path; /** * 执行路由的方法 */ private Method action; /** * 路由所在的控制器 */ private Object controller;&#125; 所有的请求在程序中是一个路由，匹配在 path 上，执行靠 action，处于 controller 中。 路由管理12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 路由管理类**/public class Routers &#123; private static final Logger LOGGER = Logger.getLogger(Routers.class.getName()); private List&lt;Route&gt; routes = new ArrayList&lt;Route&gt;(); public Routers() &#123; &#125; public void addRoute(List&lt;Route&gt; routes)&#123; routes.addAll(routes); &#125; public void addRoute(Route route)&#123; routes.add(route); &#125; public void removeRoute(Route route)&#123; routes.remove(route); &#125; public void addRoute(String path, Method action, Object controller)&#123; Route route = new Route(); route.setPath(path); route.setAction(action); route.setController(controller); routes.add(route); LOGGER.info(&quot;Add Route：[&quot; + path + &quot;]&quot;); &#125; public List&lt;Route&gt; getRoutes() &#123; return routes; &#125; public void setRoutes(List&lt;Route&gt; routes) &#123; this.routes = routes; &#125; &#125; 路由匹配1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 路由匹配器，用于匹配路由 */public class RouteMatcher &#123; private List&lt;Route&gt; routes; public RouteMatcher(List&lt;Route&gt; routes) &#123; this.routes = routes; &#125; public void setRoutes(List&lt;Route&gt; routes) &#123; this.routes = routes; &#125; /** * 根据path查找路由 * @param path 请求地址 * @return 返回查询到的路由 */ public Route findRoute(String path) &#123; String cleanPath = parsePath(path); List&lt;Route&gt; matchRoutes = new ArrayList&lt;Route&gt;(); for (Route route : this.routes) &#123; if (matchesPath(route.getPath(), cleanPath)) &#123; matchRoutes.add(route); &#125; &#125; // 优先匹配原则 giveMatch(path, matchRoutes); return matchRoutes.size() &gt; 0 ? matchRoutes.get(0) : null; &#125; private void giveMatch(final String uri, List&lt;Route&gt; routes) &#123; Collections.sort(routes, new Comparator&lt;Route&gt;() &#123; @Override public int compare(Route o1, Route o2) &#123; if (o2.getPath().equals(uri)) &#123; return o2.getPath().indexOf(uri); &#125; return -1; &#125; &#125;); &#125; private boolean matchesPath(String routePath, String pathToMatch) &#123; routePath = routePath.replaceAll(PathUtil.VAR_REGEXP, PathUtil.VAR_REPLACE); return pathToMatch.matches(&quot;(?i)&quot; + routePath); &#125; private String parsePath(String path) &#123; path = PathUtil.fixPath(path); try &#123; URI uri = new URI(path); return uri.getPath(); &#125; catch (URISyntaxException e) &#123; return null; &#125; &#125;&#125; 控制器设计上下文环境123456789101112131415161718192021222324252627/** * 当前线程上下文环境 */public final class MarioContext &#123; private static final ThreadLocal&lt;MarioContext&gt; CONTEXT = new ThreadLocal&lt;MarioContext&gt;(); private ServletContext context; private Request request; private Response response; private MarioContext() &#123; &#125; public static MarioContext me()&#123; return CONTEXT.get(); &#125; public static void initContext(ServletContext context, Request request, Response response) &#123; MarioContext marioContext = new MarioContext(); marioContext.context = context; marioContext.request = request; marioContext.response = response; CONTEXT.set(marioContext); &#125;&#125; 控制器核心对象 接收用户请求 查找路由 找到即执行配置的方法 找不到你看到的应该是404 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125/** * Mario MVC核心处理器 * */public class MarioFilter implements Filter &#123; private static final Logger LOGGER = Logger.getLogger(MVCFilter.class.getName()); private RouteMatcher routeMatcher = new RouteMatcher(new ArrayList&lt;Route&gt;()); private ServletContext servletContext; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; Mario mario = Mario.me(); if(!mario.isInit())&#123; String className = filterConfig.getInitParameter(&quot;bootstrap&quot;); Bootstrap bootstrap = this.getBootstrap(className); bootstrap.init(mario); Routers routers = mario.getRouters(); if(null != routers)&#123; routeMatcher.setRoutes(routers.getRoutes()); &#125; servletContext = filterConfig.getServletContext(); mario.setInit(true); &#125; &#125; private Bootstrap getBootstrap(String className) &#123; if(null != className)&#123; try &#123; Class&lt;?&gt; clazz = Class.forName(className); Bootstrap bootstrap = (Bootstrap) clazz.newInstance(); return bootstrap; &#125; catch (ClassNotFoundException e) &#123; throw new RuntimeException(e); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; throw new RuntimeException(&quot;init bootstrap class error!&quot;); &#125; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain chain) throws IOException, ServletException &#123; HttpServletRequest request = (HttpServletRequest) servletRequest; HttpServletResponse response = (HttpServletResponse) servletResponse; request.setCharacterEncoding(Const.DEFAULT_CHAR_SET); response.setCharacterEncoding(Const.DEFAULT_CHAR_SET); // 请求的uri String uri = PathUtil.getRelativePath(request); LOGGER.info(&quot;Request URI：&quot; + uri); Route route = routeMatcher.findRoute(uri); // 如果找到 if (route != null) &#123; // 实际执行方法 handle(request, response, route); &#125; else&#123; chain.doFilter(request, response); &#125; &#125; private void handle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Route route)&#123; // 初始化上下文 Request request = new Request(httpServletRequest); Response response = new Response(httpServletResponse); MarioContext.initContext(servletContext, request, response); Object controller = route.getController(); // 要执行的路由方法 Method actionMethod = route.getAction(); // 执行route方法 executeMethod(controller, actionMethod, request, response); &#125; /** * 获取方法内的参数 */ private Object[] getArgs(Request request, Response response, Class&lt;?&gt;[] params)&#123; int len = params.length; Object[] args = new Object[len]; for(int i=0; i&lt;len; i++)&#123; Class&lt;?&gt; paramTypeClazz = params[i]; if(paramTypeClazz.getName().equals(Request.class.getName()))&#123; args[i] = request; &#125; if(paramTypeClazz.getName().equals(Response.class.getName()))&#123; args[i] = response; &#125; &#125; return args; &#125; /** * 执行路由方法 */ private Object executeMethod(Object object, Method method, Request request, Response response)&#123; int len = method.getParameterTypes().length; method.setAccessible(true); if(len &gt; 0)&#123; Object[] args = getArgs(request, response, method.getParameterTypes()); return ReflectUtil.invokeMehod(object, method, args); &#125; else &#123; return ReflectUtil.invokeMehod(object, method); &#125; &#125; @Override public void destroy() &#123; &#125;&#125; Servlet过滤器调用端配置 12345678910111213141516&lt;web-app&gt; &lt;display-name&gt;Archetype Created Web Application&lt;/display-name&gt; &lt;filter&gt; &lt;filter-name&gt;test&lt;/filter-name&gt; &lt;filter-class&gt;com.test.MarioFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;bootstrap&lt;/param-name&gt; &lt;param-value&gt;com.test.App&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;test&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 配置设计 添加路由 读取资源文件 读取配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public final class Mario &#123; /** * 存放所有路由 */ private Routers routers; /** * 配置加载器 */ private ConfigLoader configLoader; /** * 框架是否已经初始化 */ private boolean init = false; private Mario() &#123; routers = new Routers(); configLoader = new ConfigLoader(); &#125; public boolean isInit() &#123; return init; &#125; public void setInit(boolean init) &#123; this.init = init; &#125; private static class MarioHolder &#123; private static Mario ME = new Mario(); &#125; public static Mario me()&#123; return MarioHolder.ME; &#125; public Mario addConf(String conf)&#123; configLoader.load(conf); return this; &#125; public String getConf(String name)&#123; return configLoader.getConf(name); &#125; public Mario addRoutes(Routers routers)&#123; this.routers.addRoute(routers.getRoutes()); return this; &#125; public Routers getRouters() &#123; return routers; &#125; /** * 添加路由 * @param path 映射的PATH * @param methodName 方法名称 * @param controller 控制器对象 * @return 返回Mario */ public Mario addRoute(String path, String methodName, Object controller)&#123; try &#123; Method method = controller.getClass().getMethod(methodName, Request.class, Response.class); this.routers.addRoute(path, method, controller); &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; catch (SecurityException e) &#123; e.printStackTrace(); &#125; return this; &#125; &#125; 调用端 12345678public class App implements Bootstrap &#123; @Override public void init(Mario mario) &#123; Index index = new Index(); mario.addRoute(&quot;/&quot;, &quot;index&quot;, index); mario.addRoute(&quot;/html&quot;, &quot;html&quot;, index); &#125;&#125; 视图设计123456789101112131415161718192021222324252627282930313233343536373839404142/** * JSP渲染实现 */public class JspRender implements Render &#123; @Override public void render(String view, Writer writer) &#123; String viewPath = this.getViewPath(view); HttpServletRequest servletRequest = MarioContext.me().getRequest().getRaw(); HttpServletResponse servletResponse = MarioContext.me().getResponse().getRaw(); try &#123; servletRequest.getRequestDispatcher(viewPath).forward(servletRequest, servletResponse); &#125; catch (ServletException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private String getViewPath(String view)&#123; Mario mario = Mario.me(); String viewPrfix = mario.getConf(Const.VIEW_PREFIX_FIELD); String viewSuffix = mario.getConf(Const.VIEW_SUFFIX_FIELD); if (null == viewSuffix || viewSuffix.equals(&quot;&quot;)) &#123; viewSuffix = Const.VIEW_SUFFIX; &#125; if (null == viewPrfix || viewPrfix.equals(&quot;&quot;)) &#123; viewPrfix = Const.VIEW_PREFIX; &#125; String viewPath = viewPrfix + &quot;/&quot; + view; if (!view.endsWith(viewSuffix)) &#123; viewPath += viewSuffix; &#125; return viewPath.replaceAll(&quot;[/]+&quot;, &quot;/&quot;); &#125; &#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven私服nexus3.x环境配置]]></title>
    <url>%2F2018%2F04%2F22%2Fmaven01%2F</url>
    <content type="text"><![CDATA[私服是指私有服务器，是架设在局域网的一种特殊的远程仓库，目的是代理远程仓库及部署第三方构建。有了私服之后，当 Maven 需要下载构件时，直接请求私服，私服上存在则下载到本地仓库；否则，私服请求外部的远程仓库，将构件下载到私服，再提供给本地仓库下载。 Nexus是一个强大的Maven仓库管理器，它极大地简化了本地内部仓库的维护和外部仓库的访问。如果使用了公共的Maven仓库服务器，可以从Maven中央仓库下载所需要的构件（Artifact），但这通常不是一个好的做法。正常做法是在本地架设一个本地Maven仓库服务器，利用Nexus私服可以只在一个地方就能够完全控制访问和部署在你所维护仓库中的每个Artifact。 Nexus优点为什么要构建Nexus私服？好处我随便列几点： Nexus在代理远程仓库的同时维护本地仓库，以降低中央仓库的负荷,节省外网带宽和时间，Nexus私服就可以满足这样的需要。 Nexus是一套“开箱即用”的系统不需要数据库，它使用文件系统加Lucene来组织数据。 Nexus使用ExtJS来开发界面，利用Restlet来提供完整的REST APIs，并能通过插件和各种IDE集成。 Nexus支持WebDAV与LDAP安全身份认证。 Nexus还提供了强大的仓库管理功能，构件搜索功能，它基于REST，提供友好的UI，占用较少的内存，基于简单文件系统而非数据库。 安装我的环境是centos7.2 + JDK8 + Maven3，首先需要安装 JDK8 和 Maven3，这里不多讲。 去官网下载最新的 download nexus 下载文件nexus-3.6.0-02-unix.tar.gz，解压缩。123tar zxf nexus-3.6.0-02-unix.tar.gz -C /usr/local/cd /usr/local/mv nexus-3.6.0-02/ nexus 启动：1./nexus/bin/nexus start 默认端口8081，如果开了防火墙，就把这个端口放开：1firewall-cmd --zone=public --add-port=8081/tcp --permanent 启动之后，运行命令lsof -i:8081可查看是否成功启动了。 Nexus默认的端口是8081，可以在etc/nexus-default.properties配置中修改。 Nexus默认的用户名密码是admin/admin123 当遇到奇怪问题时，重启nexus，重启后web界面要1分钟左右后才能访问。 设置开机启动123ln -s /usr/local/nexus-3.6.0-02/bin/nexus /etc/init.d/nexus3chkconfig --add nexus3chkconfig nexus3 on 修改nexus用户为root1vim /usr/local/nexus/bin/nexus.rc 12//设置run_as_user=&quot;root&quot; 修改 nexus3 启动时要使用的 jdk 版本1vim /usr/local/nexus/bin/nexus 12#14行INSTALL4J_JAVA_HOME_OVERRIDE=/usr/share/java/jdk1.8.0_131 Nexus的工作目录是sonatype-work（路径一般在nexus同级目录下），日志文件也在这里。123ls sonatype-work/nexus3/backup blobs cache db elasticsearch etc generated-bundles health-check instances keystores lock log orient port tmp 访问：http://localhost:8081，效果如下： 使用默认的管理员admin/admin123登录，进入管理界面： 用户和角色可以点击上面的“设置”图标，在“设置”里可以添加用户、角色，对接LDAP等的设置。 仓库最核心的是仓库管理 默认的这几个仓库我解释一下： maven-central：maven中央库，默认从https://repo1.maven.org/maven2/拉取jar maven-releases：私库发行版jar，初次安装请将Deployment policy设置为Allow redeploy maven-snapshots：私库快照（调试版本）jar maven-public：仓库分组，把上面三个仓库组合在一起对外提供服务，在本地maven基础配置settings.xml中使用。 Nexus默认的仓库类型有以下四种： group(仓库组类型)：又叫组仓库，用于方便开发人员自己设定的仓库； hosted(宿主类型)：内部项目的发布仓库（内部开发人员，发布上去存放的仓库）； proxy(代理类型)：从远程中央仓库中寻找数据的仓库（可以点击对应的仓库的Configuration页签下Remote Storage属性的值即被代理的远程仓库的路径）； virtual(虚拟类型)：虚拟仓库（这个基本用不到，重点关注上面三个仓库的使用）； Policy(策略): 表示该仓库为发布(Release)版本仓库还是快照(Snapshot)版本仓库； 由于访问中央仓库有时候会比较慢，这里我添加一个阿里云的代理仓库，然后优先级放到默认中央库之前,，阿里云的maven仓库url为http://maven.aliyun.com/nexus/content/groups/public 然后再public组里面讲这个aliyun-proxy仓库加入，排在maven-central之前即可。 Nexus仓库分类的概念 1）Maven可直接从宿主仓库下载构件,也可以从代理仓库下载构件,而代理仓库间接的从远程仓库下载并缓存构件 2）为了方便,Maven可以从仓库组下载构件,而仓库组并没有时间的内容(下图中用虚线表示,它会转向包含的宿主仓库或者代理仓库获得实际构件的内容) Nexus的调度任务默认安装好之后是没有索引和jar文件的，因为你要自己定义任务去执行。 Nexus提供了一系列可配置的调度任务来方便用户管理系统。用户可以设定这些任务运行的方式，例如每天、每周等。调度任务会在适当的时候在后台运行。 要建立一个调度任务，单击左边导航菜单中的Tasks，点击Create Task，然后选择一个任务类型。 以下几种常用类型的调度任务： Execute script：执行自定义脚本 Purge开头：清理一些不使用的资源。 Rebuild repository index：为仓库重新编纂索引，从远仓库下载最新的索引。 Rebuild Maven repository metadata：基于仓库内容重新创建仓库元数据文件，同时重新创建每个文件的校验和md5与sha1。 Remove snapshots from Maven repository：把快照删了，这个是在稳定版发布后清除 比如我新建一个重构索引的任务，然后选择aliyun仓库，让它把远程索引取下来，手动执行。不过最好别这样做，因为需要很大的硬盘空间。 最好是让它自己去维护，请求一个依赖的时候如果私服没有会自动去远仓库取的。 Nexus搜索页这个不需要登录就可以访问，用来查询jar包。支持模糊查询 Blob Stores文件存储的地方，创建一个目录的话，对应文件系统的一个目录，可供仓库上传文件使用，如图所示： 本地Maven使用私服安装和配置好之后，在开发中如何使用呢。可在maven的默认配置settings.xml中修改如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;servers&gt; &lt;server&gt; &lt;id&gt;releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt;&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;Nexus&lt;/id&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt;&lt;activeProfiles&gt; &lt;activeProfile&gt;dev&lt;/activeProfile&gt;&lt;/activeProfiles&gt; 如果要发布自己的jar到私服，就需要修改工程的pom.xml，添加如下内容，否则什么都不用做： 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;releases&lt;/id&gt; &lt;name&gt;Releases&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;snapshots&lt;/id&gt; &lt;name&gt;Snapshot&lt;/name&gt; &lt;url&gt;http://123.207.66.156:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; 注意上面的repository的id值一定要跟settings.xml文件中配置的server一致。 上传到Nexus上，使用 mvn deploy 即可，开发的时候请使用snapshot版本，也就是version的后缀必须是-SNAPSHOT。 1234&lt;groupId&gt;com.enzhico&lt;/groupId&gt;&lt;artifactId&gt;micro-pay-sdk&lt;/artifactId&gt;&lt;version&gt;1.2-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;jar&lt;/packaging&gt; 上次成功后再去私服仓库查询快照版发现已经成功上传： 第三方Jar上传到Nexus 12345678mvn deploy:deploy-file \ -DgroupId=&lt;group-id&gt; \ -DartifactId=&lt;artifact-id&gt; \ -Dversion=&lt;version&gt; \ -Dpackaging=&lt;type-of-packaging&gt; \ -Dfile=&lt;path-to-file&gt; \ -DrepositoryId=&lt;server-id-settings.xml&gt; \ -Durl=&lt;url-of-the-repository-to-deploy&gt; -DrepositoryId的值即为在setttings.xml里面配置的server id。 上次不同JDK版本pom.xml里面配置多个profile，其中一个默认的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;$&#123;jar.source&#125;&lt;/source&gt; &lt;target&gt;$&#123;jar.target&#125;&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;deploy&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;deploy&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;default&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;jar.source&gt;1.8&lt;/jar.source&gt; &lt;jar.target&gt;1.8&lt;/jar.target&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;jdk16&lt;/id&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;classifier&gt;jdk16&lt;/classifier&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;properties&gt; &lt;jar.source&gt;1.6&lt;/jar.source&gt; &lt;jar.target&gt;1.6&lt;/jar.target&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 上面我定义了两个profile，那么打包或者发布的时候可指定不同的JDK版本： 1234# 默认版本JDK1.8mvn clean &amp;&amp; mvn deploy# JDK1.6版本mvn clean &amp;&amp; mvn deploy -P jdk16 第一条命令打包使用默认的profile，编译的版本是1.8，生成的文件是xxx-SNAPSHOT.jar；而第二条命令打包指定使用jdk16这个profile，编译版本是1.6，生成的文件是xxx-SNAPSHOT-jdk16.jar。 项目中引用的时候可通过指定classifier： 123456&lt;dependency&gt; &lt;groupId&gt;com.enzhico&lt;/groupId&gt; &lt;artifactId&gt;adm-traffic-common-model&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;classifier&gt;jdk16&lt;/classifier&gt;&lt;/dependency&gt; 发布源码和文档如果你还想发布源码和javadoc，那么需要使用maven插件，我把插件配置列出来： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.7.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.10.4&lt;/version&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;aggregate&gt;true&lt;/aggregate&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;docencoding&gt;UTF-8&lt;/docencoding&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;version&gt;2.8.2&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;deploy&lt;/id&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;deploy&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 发布javadoc的时候，每个方法注释必须遵循规范，比如参数、返回值、异常都应该有说明。 打包或发布的时候如果想跳过测试，加一个参数：1mvn clean &amp;&amp; mvn deploy -DskipTests=true 特此声明：本文非作者原创，转自 https://github.com/yidao620c]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>nexus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CompletableFuture解析]]></title>
    <url>%2F2018%2F04%2F08%2FCompletableFuture01%2F</url>
    <content type="text"><![CDATA[初出茅庐什么是CompletableFuture？个人理解，CompletableFuture是针对Java 5中Future的一个扩展，可能有人会问什么是Future，Future是对将来某个时间点完成的结果。 先简单看一个Future的例子 12345678910111213141516171819202122232425262728import java.util.concurrent.*;public class FutureAndCallableExample &#123; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ExecutorService executorService = Executors.newSingleThreadExecutor(); Callable&lt;String&gt; callable = () -&gt; &#123; // Perform some computation System.out.println(&quot;Entered Callable&quot;); Thread.sleep(2000); return &quot;Hello from Callable&quot;; &#125;; System.out.println(&quot;Submitting Callable&quot;); Future&lt;String&gt; future = executorService.submit(callable); // This line executes immediately System.out.println(&quot;Do something else while callable is getting executed&quot;); System.out.println(&quot;Retrieve the result of the future&quot;); // Future.get() blocks until the result is available String result = future.get(); System.out.println(result); executorService.shutdown(); &#125;&#125; 123456# OutputSubmitting CallableDo something else while callable is getting executedRetrieve the result of the futureEntered CallableHello from Callable Future接口包括以下几个方法 boolean cancel(boolean) boolean isCancelled() boolean isDone() V get() V get(long,TimeUnit) 既然有了Future这种基于异步的接口，那么为什么Java8又推出了CompletableFuture呢？ 来看下Future的几个局限性 不能手动触发完成 如果不阻塞，无法对Future的结果进行进一步操作 不支持链式操作 不支持组合操作 无异常处理 小试牛刀一个CompletableFuture的例子 12345CompletableFuture&lt;String&gt; completableFuture = new CompletableFuture&lt;String&gt;();// 如果你不手动触发完成的操作，get()将被永远阻塞String result = completableFuture.get()completableFuture.complete(&quot;Future&apos;s Result&quot;) CompletableFuture基本使用 static CompletableFuture runAsync(Runnable runnable) static CompletableFuture runAsync(Runnable runnable, Executor executor) static CompletableFuture supplyAsync(Supplier supplier) static CompletableFuture supplyAsync(Supplier supplier, Executor executor) 12345678910// 当不需要获取返回值使用runAsync() CompletableFuture&lt;Void&gt; future = CompletableFuture.runAsync(() -&gt; &#123; // Simulate a long-running Job try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; System.out.println(&quot;I&apos;ll run in a separate thread than the main thread.&quot;);&#125;); 123456789// 当需要获取返回值时使用supplyAsync()CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Result of the asynchronous computation&quot;;&#125;); 12345678910// 指定线程池的使用Executor executor = Executors.newFixedThreadPool(10);CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Result of the asynchronous computation&quot;;&#125;, executor); 这里线程池的数量的大小有一个公式的可以作为参考 Nthreads = NCPU UCPU (1 + W/C) NCPU是处理器的核数目，可以通过Runtime.getRuntime().availableProcessors()得到 UCPU是cpu的利用率，介于0~1之间 W/C是等待时间与计算时间的比率 勤学苦练CompletableFuture的链式操作 thenApply() thenAccept() thenRun() 123456789101112131415// thenApply()对CompletableFuture的记过进行链式操作CompletableFuture&lt;String&gt; welcomeText = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Rajeev&quot;;&#125;).thenApply(name -&gt; &#123; return &quot;Hello &quot; + name;&#125;).thenApply(greeting -&gt; &#123; return greeting + &quot;, Welcome to the CalliCoder Blog&quot;;&#125;);System.out.println(welcomeText.get());// Prints - Hello Rajeev, Welcome to the CalliCoder Blog 123456// thenAccept()不依赖CompletableFuture的结果，但是要等到获取到结果再处理CompletableFuture.supplyAsync(() -&gt; &#123; return ProductService.getProductDetail(productId);&#125;).thenAccept(product -&gt; &#123; System.out.println(&quot;Got product detail from remote service &quot; + product.getName())&#125;); 123456// thenRun()不依赖上一操作的结果，另起一个线程处理CompletableFuture.supplyAsync(() -&gt; &#123; // Run some computation &#125;).thenRun(() -&gt; &#123; // Computation Finished.&#125;); CompletableFuture的合并操作 thenCompose() thenCombine() 123456789101112131415// thenCompose()合并两个CompletableFuture操作，但是两个操作存在依赖关系CompletableFuture&lt;User&gt; getUsersDetail(String userId) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; UserService.getUserDetails(userId); &#125;); &#125;CompletableFuture&lt;Double&gt; getCreditRating(User user) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; CreditRatingService.getCreditRating(user); &#125;);&#125;CompletableFuture&lt;Double&gt; result = getUserDetail(userId).thenCompose(user -&gt; getCreditRating(user)); 12345678910111213141516171819202122232425262728// thenCombine()合并两个无关的操作CompletableFuture&lt;Double&gt; weightInKgFuture = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return 65.0;&#125;);System.out.println(&quot;Retrieving height.&quot;);CompletableFuture&lt;Double&gt; heightInCmFuture = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return 177.8;&#125;);System.out.println(&quot;Calculating BMI.&quot;);CompletableFuture&lt;Double&gt; combinedFuture = weightInKgFuture .thenCombine(heightInCmFuture, (weightInKg, heightInCm) -&gt; &#123; Double heightInMeter = heightInCm/100; return weightInKg/(heightInMeter*heightInMeter);&#125;);System.out.println(&quot;Your BMI is - &quot; + combinedFuture.get()); CompletableFuture的批量操作 static CompletableFuture allOf(CompletableFuture&lt;?&gt;… cfs) static CompletableFuture anyOf(CompletableFuture&lt;?&gt;… cfs) 1234567891011121314151617181920212223242526272829303132333435// allOf()对多个任务进行操作CompletableFuture&lt;String&gt; downloadWebPage(String pageLink) &#123; return CompletableFuture.supplyAsync(() -&gt; &#123; // Code to download and return the web page&apos;s content &#125;);&#125; List&lt;String&gt; webPageLinks = Arrays.asList(...) // A list of 100 web page links// Download contents of all the web pages asynchronouslyList&lt;CompletableFuture&lt;String&gt;&gt; pageContentFutures = webPageLinks.stream() .map(webPageLink -&gt; downloadWebPage(webPageLink)) .collect(Collectors.toList());// Create a combined Future using allOf()CompletableFuture&lt;Void&gt; allFutures = CompletableFuture.allOf( pageContentFutures.toArray(new CompletableFuture[pageContentFutures.size()]));// When all the Futures are completed, call `future.join()` to get their results and collect the results in a list -CompletableFuture&lt;List&lt;String&gt;&gt; allPageContentsFuture = allFutures.thenApply(v -&gt; &#123; return pageContentFutures.stream() .map(pageContentFuture -&gt; pageContentFuture.join()) .collect(Collectors.toList());&#125;);// Count the number of web pages having the &quot;CompletableFuture&quot; keyword.CompletableFuture&lt;Long&gt; countFuture = allPageContentsFuture.thenApply(pageContents -&gt; &#123; return pageContents.stream() .filter(pageContent -&gt; pageContent.contains(&quot;CompletableFuture&quot;)) .count();&#125;);System.out.println(&quot;Number of Web Pages having CompletableFuture keyword - &quot; + countFuture.get()); 12345678910111213141516171819202122232425262728293031// anyOf()当有一个任务执行完成便返回结果CompletableFuture&lt;String&gt; future1 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Result of Future 1&quot;;&#125;);CompletableFuture&lt;String&gt; future2 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Result of Future 2&quot;;&#125;);CompletableFuture&lt;String&gt; future3 = CompletableFuture.supplyAsync(() -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; throw new IllegalStateException(e); &#125; return &quot;Result of Future 3&quot;;&#125;);CompletableFuture&lt;Object&gt; anyOfFuture = CompletableFuture.anyOf(future1, future2, future3);System.out.println(anyOfFuture.get()); // Result of Future 2 CompletableFuture异常处理 exceptionally() handle() 123456789101112131415161718Integer age = -1;// exceptionally()如果你处理过一次该错误，则回调链中不会再传播该错误CompletableFuture&lt;String&gt; maturityFuture = CompletableFuture.supplyAsync(() -&gt; &#123; if(age &lt; 0) &#123; throw new IllegalArgumentException(&quot;Age can not be negative&quot;); &#125; if(age &gt; 18) &#123; return &quot;Adult&quot;; &#125; else &#123; return &quot;Child&quot;; &#125;&#125;).exceptionally(ex -&gt; &#123; System.out.println(&quot;Oops! We have an exception - &quot; + ex.getMessage()); return &quot;Unknown!&quot;;&#125;);System.out.println(&quot;Maturity : &quot; + maturityFuture.get()); 123456789101112131415161718192021Integer age = -1;// handle(res,ex)异常存在则res为null，否则ex为nullCompletableFuture&lt;String&gt; maturityFuture = CompletableFuture.supplyAsync(() -&gt; &#123; if(age &lt; 0) &#123; throw new IllegalArgumentException(&quot;Age can not be negative&quot;); &#125; if(age &gt; 18) &#123; return &quot;Adult&quot;; &#125; else &#123; return &quot;Child&quot;; &#125;&#125;).handle((res, ex) -&gt; &#123; if(ex != null) &#123; System.out.println(&quot;Oops! We have an exception - &quot; + ex.getMessage()); return &quot;Unknown!&quot;; &#125; return res;&#125;);System.out.println(&quot;Maturity : &quot; + maturityFuture.get()); 华山论剑待续。。。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识Rocketmq(二)]]></title>
    <url>%2F2017%2F01%2F26%2Frocketmq03%2F</url>
    <content type="text"><![CDATA[Rocketmq普通消息消费这里是rocketmq-example的示例代码12345678910111213141516171819202122232425262728/** * Producer，发送消息 * */public class Producer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;common_message&quot;); producer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); producer.start(); for (int i = 0; i &lt; 1000; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;,// topic &quot;TagA&quot;,// tag (&quot;Hello RocketMQ &quot; + i).getBytes()// body ); SendResult sendResult = producer.send(msg); System.out.println(sendResult); &#125; catch (Exception e) &#123; e.printStackTrace(); Thread.sleep(1000); &#125; &#125; producer.shutdown(); &#125;&#125; 12345678910111213141516171819202122232425262728293031/** * Consumer，订阅消息 */public class Consumer &#123; public static void main(String[] args) throws InterruptedException, MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;common_message&quot;); consumer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(&quot;TopicTest&quot;, &quot;*&quot;); consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.println(Thread.currentThread().getName() + &quot; Receive New Messages: &quot; + msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); consumer.start(); System.out.println(&quot;Consumer Started.&quot;); &#125;&#125; 这里没有过多的赘述，只是普通的消息生产与消费，需要指出的是，common_message是groupname，它的意义在于：作为生产者，当发送消息的一个节点宕机时，与它处于同一个group的其它节点可以发送消息；作为消费者，同样当消费者的一个节点宕机时，处于同一group的其它节点可以进行消费，实现了高可用的思想。 Rocketmq顺序消息消费首先同样给出代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Producer，发送顺序消息 */public class Producer &#123; public static void main(String[] args) &#123; try &#123; DefaultMQProducer producer = new DefaultMQProducer(&quot;order_message&quot;); producer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); producer.start(); String[] tags = new String[] &#123; &quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot; &#125;; for (int i = 0; i &lt; 100; i++) &#123; // 订单ID相同的消息要有序 int orderId = i % 10; Message msg = new Message(&quot;topic_one&quot;, tags[i % tags.length], &quot;KEY&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, orderId); System.out.println(sendResult); &#125; producer.shutdown(); &#125; catch (MQClientException e) &#123; e.printStackTrace(); &#125; catch (RemotingException e) &#123; e.printStackTrace(); &#125; catch (MQBrokerException e) &#123; e.printStackTrace(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 顺序消息消费，带事务方式（应用可控制Offset什么时候提交） */public class Consumer &#123; public static void main(String[] args) throws MQClientException &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(&quot;order_message&quot;); consumer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); consumer.subscribe(&quot;topic_one&quot;, &quot;TagA || TagC || TagD&quot;); consumer.registerMessageListener(new MessageListenerOrderly() &#123; AtomicLong consumeTimes = new AtomicLong(0); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); System.out.println(Thread.currentThread().getName() + &quot; Receive New Messages: &quot; + msgs); this.consumeTimes.incrementAndGet(); if ((this.consumeTimes.get() % 2) == 0) &#123; return ConsumeOrderlyStatus.SUCCESS; &#125; else if ((this.consumeTimes.get() % 3) == 0) &#123; return ConsumeOrderlyStatus.ROLLBACK; &#125; else if ((this.consumeTimes.get() % 4) == 0) &#123; return ConsumeOrderlyStatus.COMMIT; &#125; else if ((this.consumeTimes.get() % 5) == 0) &#123; context.setSuspendCurrentQueueTimeMillis(3000); return ConsumeOrderlyStatus.SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println(&quot;Consumer Started.&quot;); &#125;&#125; 这里需要注意以下几点： 顺序消费的实现原理是生产者将需要有序消费的消息放在同一个队列中，并且该队列存储在MQ集群中的一个节点，不能分散存储，这样消费者只需要从该节点上拉取消费即可。 消费者在消费时采用了多线程的方式，那么有心的你可能会有这样的疑问，即使消息可以按顺序到达，但是消费的快慢仍然无法保证有序。rocketmq本身实现了有序消费时线程间等待的功能，所以这个问题不用担心。 context.setAutoCommit(true);这句话的含义：一是删除msgTreeMapTemp里的消息，防止消息堆积，二是把拉消息的偏移量更新到本地，然后定时更新到broker。具体为什么会有这种设置，笔者暂不确定，不过设置为false时你会发现重复消费的情况。 Rocektmq事务消息消费以下是示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 发送事务消息例子 * */public class TransactionProducer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; TransactionCheckListener transactionCheckListener = new TransactionCheckListenerImpl(); TransactionMQProducer producer = new TransactionMQProducer(&quot;trans_message&quot;); // 事务回查最小并发数 producer.setCheckThreadPoolMinSize(2); // 事务回查最大并发数 producer.setCheckThreadPoolMaxSize(2); // 队列数 producer.setCheckRequestHoldMax(2000); producer.setTransactionCheckListener(transactionCheckListener); producer.setNamesrvAddr(&quot;192.168.2.201:9876;192.168.2.202:9876&quot;); producer.start(); String[] tags = new String[] &#123; &quot;TagA&quot;, &quot;TagB&quot;, &quot;TagC&quot;, &quot;TagD&quot;, &quot;TagE&quot; &#125;; TransactionExecuterImpl tranExecuter = new TransactionExecuterImpl(); for (int i = 0; i &lt; 1; i++) &#123; try &#123; Message msg = new Message(&quot;TopicTest&quot;, tags[i % tags.length], &quot;KEY&quot; + i, (&quot;Hello RocketMQ &quot; + i).getBytes()); SendResult sendResult = producer.sendMessageInTransaction(msg, tranExecuter, null); System.out.println(sendResult); Thread.sleep(10); &#125; catch (MQClientException e) &#123; e.printStackTrace(); &#125; &#125; for (int i = 0; i &lt; 100000; i++) &#123; Thread.sleep(1000); &#125; producer.shutdown(); &#125;&#125; 123456789101112131415161718192021222324/** * 执行本地事务 */public class TransactionExecuterImpl implements LocalTransactionExecuter &#123; private AtomicInteger transactionIndex = new AtomicInteger(4); @Override public LocalTransactionState executeLocalTransactionBranch(final Message msg, final Object arg) &#123; int value = transactionIndex.getAndIncrement(); if (value == 0) &#123; throw new RuntimeException(&quot;Could not find db&quot;); &#125; else if ((value % 5) == 0) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else if ((value % 4) == 0) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; return LocalTransactionState.UNKNOW; &#125;&#125; 12345678910111213141516171819202122232425/** * 未决事务，服务器回查客户端 */public class TransactionCheckListenerImpl implements TransactionCheckListener &#123; private AtomicInteger transactionIndex = new AtomicInteger(0); @Override public LocalTransactionState checkLocalTransactionState(MessageExt msg) &#123; System.out.println(&quot;server checking TrMsg &quot; + msg.toString()); int value = transactionIndex.getAndIncrement(); if ((value % 6) == 0) &#123; throw new RuntimeException(&quot;Could not find db&quot;); &#125; else if ((value % 5) == 0) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else if ((value % 4) == 0) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125;// return LocalTransactionState.UNKNOW; return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125; 这里举一个形象的例子生产者首先向MQ发送消息，然后执行本地事务，当事务执行成功则再发送确认消息，否则会回滚本地事务。根据图示我们做以下几个说明： 图中1操作：生产者向MQ发送一条消息，这条消息为TransactionPreparedType,被保存到commitlog中，并返回给生产者offset和messageid，但它不会保存在consumerqueue中，因此不会被消费，这里需要读者自行理解rocketmq的存储规律。 当本地事务执行结束（即TransactionExecuterImpl）后，会根据返回结果确认本地事务是否执行成功。返回结果包括COMMIT_MESSAGE、ROLLBACK_MESSAGE、UNKNOWN。当结果为COMMIT_MESSAGE时会再向MQ发送一条消息，并存放在consumerQueue中提供消费者消费。当结果为ROLLBACK_MESSAGE时则同样发送一条消息但消息体为空。当结果为UNKONWN时则MQ会执行自动检测机制（即TransactionCheckListenerImpl），会回调生产者的方法根据该消息的状态做相应处理。 Rocketmq消息重试机制Rocketmq重试机制从三个方面来实现重试的策略。包括生产者向MQ发送消息失败的重试，消费者从MQ拉取消息失败的重试以及消费者处理消息异常时消息的重试。如图所示 生产者的消息重试策略我们通常可以设置重试的最大次数以及重试的超时时间，也就是消息发送到MQ的超时时间。 消费者获取消息的重试策略Rocketmq自身已经为用户实现了，默认是16次尝试，间隔时间为1s，30s,60s…… 消费者处理时的异常通过给MQ返回值来判定，ConsumeConcurrentlyStatus.CONSUME_SUCCESS表示处理成功，ConsumeConcurrentlyStatus.RECONSUME_LATER表示处理失败，如果失败则MQ重新发送该消息，直到该消息处理成功。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rocketmq多master搭建]]></title>
    <url>%2F2017%2F01%2F24%2FRocketmq01%2F</url>
    <content type="text"><![CDATA[Rocketmq物理部署结构图 安装包下载 注意： 以下操作每台机器都需要配置 Rocketmq目前已收录于apache下，目前版本是4.0。在此之前版本更新到3.5.8，github上release版本提供了3.5.8的源码，稳定的编译后的版本是3.2.6，所以这里我以3.2.6介绍。rocketmq3.x下载点这里。有兴趣的童鞋可以尝试4.x，地址在这里，源码采用maven编译即可，这里不过多赘述。 服务器环境 IP 用户名 角色 模式 192.168.2.201 root rocketmq-nameserver1,rocketmq-master1 Master1 192.168.2.202 root rocketmq-nameserver2,rocketmq-master2 Master2 Hosts配置信息 IP Name 192.168.2.201 rocketmq-nameserver1 192.168.2.201 rocketmq-master1 192.168.2.202 rocketmq-nameserver2 192.168.2.202 rocketmq-master2 192.168.2.201 centos201 192.168.2.202 centos202 这里需要注意一点，我在hosts信息中分别把各自主机名和对应ip配置进来，之前尝试没有配置而报错。 上传解压 上传alibaba-rocketmq-3.2.6.tar.gz文件到/usr/local/software 解压并创建软链接12tar -zxvf alibaba-rocketmq-3.2.6.tar.gz -C /usr/localln -s alibaba-rocketmq rocketmq 创建存储路径1234mkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeuemkdir /usr/local/rocketmq/store/index 修改Rocketmq的配置文件12vim /usr/local/rocketmq/conf/2m-noslave/broker-a.propertiesvim /usr/local/rocketmq/conf/2m-noslave/broker-b.properties 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割lushDiskType=ASYNC_FLUSHnamesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#ASYNC_MASTER 异步复制Master#SYNC_MASTER 同步双写Master#SLAVEbrokerRole=ASYNC_MASTER#刷盘方式#ASYNC_FLUSH 异步刷盘#SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128 修改日志配置文件12mkdir -p /usr/local/rocketmq/logscd /usr/local/rocketmq/conf &amp;&amp; sed -i &apos;s#$&#123;user.home&#125;#/usr/local/rocketmq#g&apos; *.xml 修改启动脚本参数开发环境jvm配置1vim /usr/local/rocketmq/bin/runbroker.sh 12JAVA_OPT=&quot;$&#123;JAVA_OPT&#125;&quot; -server -Xms1g -Xmx1g -Xmn512m-XX:PermSize=128m -XX:MaxPermSize=320m&quot; 1vim /usr/local/rocketmq/bin/runserver.sh 12JAVA_OPT=&quot;$&#123;JAVA_OPT&#125;&quot; -server -Xms1g -Xmx1g -Xmn512m-XX:PermSize=128m -XX:MaxPermSize=320m&quot; 启动NameServer12cd /usr/local/rocketmq/binnohup sh mqnamesrv &amp; 启动BrokerServer brokerA(192.168.2.201) 12cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-a.properties &gt;/dev/null 2&gt;&amp;1 &amp; brokerB(192.168.2.202) 12cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-noslave/broker-b.properties &gt;/dev/null 2&gt;&amp;1 &amp; 查看是否启动成功1234netstat -ntlpjpstail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/broker.logtail -f -n 500 /usr/local/rocketmq/logs/rocketmqlogs/namesrc.log 停止服务及数据清理123cd /usr/local/rocketmq/binsh mqshutdown brokersh mqshutdown namesrv 12345rm -rf /usr/local/rocketmq/storemkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeuemkdir /usr/local/rocketmq/store/index 多Master多Slave模式配置多master多slave模式的方式和本文介绍的多master方式大体相同，不过需要注意以下几点。 Hosts配置信息 IP Name 192.168.2.201 rocketmq-nameserver1 192.168.2.201 rocketmq-master1 192.168.2.202 rocketmq-nameserver2 192.168.2.202 rocketmq-master2 192.168.2.203 rocketmq-nameserver3 192.168.2.203 rocketmq-master1-slave 192.168.2.204 rocketmq-nameserver4 192.168.2.204 rocketmq-master2-slave 192.168.2.201 centos201 192.168.2.202 centos202 192.168.2.203 centos203 192.168.2.204 centos204 选择配置文件这里需要编辑对应的配置文件：在/usr/local/rocketmq/conf下存在三个配置文件，分别为2m-2s-async,2m-2s-sync,2m-noslave。当我们需要搭建多主多从的集群环境时，考虑异步复制还是同步双写模式来选择对应配置文件进行修改。 配置文件修改配置文件修改注意以下几点123456789101112brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样,若为从节点，则与对应主节点名字相同brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割lushDiskType=ASYNC_FLUSHnamesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876;rocketmq-nameserver3:9876;rocketmq-nameserver4:9876#Broker 的角色#ASYNC_MASTER 异步复制Master#SYNC_MASTER 同步双写Master#SLAVEbrokerRole=ASYNC_MASTER]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识Rocketmq(一)]]></title>
    <url>%2F2017%2F01%2F20%2Frocketmq02%2F</url>
    <content type="text"><![CDATA[产品发展历史 Metaq（Metamorphosis） 1.x 由开源社区 killme2008 维护，开源社区非常常活跃。 https://github.com/killme2008/Metamorphosis Metaq 2.x 亍2012年10月份上线，在淘宝内部被广泛使用。 RocketMQ 3.x Metaq正式更名为Rocketmq，集群由第三方的zookeeper转化为自身的nameserver。开源社区地址：https://github.com/alibaba/RocketMQ RocketMQ 4.xRocketmq捐赠于apache，开源地址：https://github.com/apache/incubator-rocketmq 专业术语 Producer：消息生产者，负责产生消息，一般有业务系统产生消息。 Consumer：消息消费者，负责消费消息，一般由后台系统进行异步消费。 PushConsumer：Consumer的一种，应用通常向Consumer对象注册一个listener接口，一旦接受消息，Consumer对象立刻回调listener接口方法。 PullConsumer：Consumer的一种，应用通常主动调用Consumer的拉消息方法从Broker拉消息，主动权由应用控制。 Producer Group：一类Producer的集合名称，这类Producer通常収送一类消息，且发送逻辑一致。 Consumer Group：一类Consumer的集合名称，这类Consumer通常消费一类消息，且发送逻辑一致。 Broker：消息中转角色，负责存储消息，转发消息，一般也称为 Server。在 JMS 规范中称为 Provider。 广播消息：一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被Consumer Group的每个Consumer都消费一次，广播消费中的Consumer Group概念可以认为在消息划分方面没有意义。在CORBA Notification规范中，消费方式都属于广播消费。在JMS规范中，相当于JMS publish/subscribe model。 集群消费：一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其中一个Consumer Group 有 3 个实例（可能是 3 个进程程，或者 3 台机器），那么每个实例只消费其中的 3 条消息。在 CORBA Notification 规范中，无此消费方式。在 JMS 规范中， JMS point-to-point model 与之类似，但是 RocketMQ 的集群消费功能大等亍 PTP 模型。因为 RocketMQ 单个 Consumer Group 内的消费者类似亍 PTP ，但是一个 Topic/Queue 可以被多个 Consumer Group 消费。 顺序消息：消费消息的顺序要同发送消息的顺序一致，在Rocketmq中，主要指的是局部顺序，即一类消息为满足顺序性，Producer必须单线程顺序发送，且发送到同一个队列，这样Consumer就可以按照Producer发送的顺序进行消费。 普通顺序消息：顺序消息的一种。正常情况下可以保证完全的顺序消息，但是一旦通信发生异常，Broker重启，由于队列总数发生变化，哈希取模后定位的队列发生变化，产生短暂的消息顺序不一致，如果业务可以容忍这种情况，则普通顺序消息比较合适。 严格顺序消息：顺序消息的一种，无论正常或异常情况都可以保证顺序消息，但是牺牲了分布式failover特性，即Broker集群中只有有一台机器不可用，则整个集群都不可用，服务可用性大大降低。目前已知的应用只有数据库的binlog同步强依赖严格顺序消息，其他应用绝大部分都可以容忍短暂的乱序，推荐使用普通的顺序消息。 Message Queue：在Rocketmq中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储单元都是定长，访问其中的存储单元使用Offset访问，offset为java lang类型，64位，理论上讲100年内不会益出，所以认为是长度无限，另外队列只保存最近几天的数据，之前的数据会按照过期时间来删除。也可以认为Message Queue是一个长度无限的数组，offset是下标。 集群方式 单个Master这种方式的风险比较大，一旦Broker重启或者宕机，会导致整个服务不可用，不建议线上环境使用。 多个Master模式一个集群中午slave，都是master，例如两个master或者3个master。优点：单个master宕机或者重启维护对应用无影响，在磁盘配置为raid10时，即使机器宕机不可恢复情况下，消息也不会丢失（异步刷盘丢失少量数据，同步刷盘消息不丢失），性能最高。缺点：单台机器宕机期间，这台机器未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。启动方式：先启动nameserver，再启动master1，master2… 多Master，多Slave模式，异步复制每个master配置一个或多个slave，有多对master-slave，HA采用异步复制方式，主备有短暂消息延迟，毫秒级。优点：即使磁盘损坏，消息丢失的非常少，且消息的实时性不会受影响，因为Master宕机后，消息仍然可以从Slave消费，此过程对应用透明，不需要人工干预，性能同多master模式几乎一样。缺点：Master宕机，磁盘损坏情况下，会丢失少量数据。启动方式：先启动nameserver，再启动第一个master，第二个master，第一个slave，第二个slave。 多Master，多Slave模式，同步双写每个Master配置一个或多个slave，有多对master-slave，HA采用同步双写方式，主备都写成功，向应用返回成功。优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非高。缺点：性能比异步复制模式略低，大约低10%左右，发送单个消息的RT会略高。启动方式：先启动nameserver，再启动第一个master，第二个master，第一个slave，第二个slave。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>rocketmq</tag>
      </tags>
  </entry>
</search>
